model_name: "motion_translation"
output_dir: "/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_translation"
dataset:
  dataset_name: "mix"
  dataset_root: "/srv/hays-lab/scratch/sanisetty3/motionx"
  motion_rep: "body"
  text_conditioner_name: "t5-large" #"openai/clip-vit-large-patch14" #"t5-base" #"openai/clip-vit-large-patch14" #"laion/larger_clap_music_and_speech"
  text_rep: "full_text_embed"
  audio_rep: "encodec"
  hml_rep: "gc"
  motion_min_length_s: 4
  motion_max_length_s: 4
  window_size_s: 4

train:
  resume: False
  num_train_iters : 110001 #'Number of training steps
  save_steps : 10000
  logging_steps : 10
  wandb_every : 200
  evaluate_every : 10000
  eval_bs : 400
  train_bs : 2000
  gradient_accumulation_steps : 1
  learning_rate : 2e-4
  weight_decay : 1e-3
  warmup_steps : 4000
  gamma : 0.05
  lr_scheduler_type : "cosine"

fuser:
  fuse_method: [{"cross": ["text"], "input_interpolate": ["audio"]}]

translation_transformer:
  target: "core.models.generation.translation_transformer.TranslationTransformer"
  input_dim: 2
  dim : 128
  conv_depth: 2
  depth: 2
  dim_out: 2
  audio_input_dim: 128
  text_input_dim: 1024
  cond_dropout: 0.5
  flash: True
  custom: True
  var_len: False
  loss_fnc: "l2"


  
  

