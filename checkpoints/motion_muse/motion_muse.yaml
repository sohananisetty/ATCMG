model_name: "motion_muse"
output_dir: "/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse"
dataset:
  dataset_name: "mix"
  dataset_root: "/srv/hays-lab/scratch/sanisetty3/motionx"
  motion_rep: "body"
  text_rep: "full_text_embed"
  audio_rep: "encodec"
  hml_rep: "rv"
  motion_min_length_s: 3
  motion_max_length_s: 15
train:
  resume: False
  num_train_iters : 310000 #'Number of training steps
  save_steps : 10000
  logging_steps : 10
  wandb_every : 200
  evaluate_every : 10000
  eval_bs : 200
  train_bs : 200
  gradient_accumulation_steps : 1
  learning_rate : 2e-4
  weight_decay : 1e-3
  warmup_steps : 4000
  gamma : 0.05
  lr_scheduler_type : "cosine"

vqvae:
  body_config: "/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_rv/vqvae_rv.yaml"
  left_hand_config: "/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_left_hand/vqvae_left_hand.yaml"
  right_hand_config: "/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_right_hand/vqvae_right_hand.yaml"

codebooks_pattern:
  modeling: "parallel"

fuser:
  fuse_method: [{"cross": ["text"], "input_interpolate": ["audio"]}]
  #[{"cross": ["audio"], "prepend": ["text"]}]

motion_generator:
  target: "core.models.generation.motion_generator.MotionMuse"
  n_q : 1
  dim : 512
  depth: 8
  cond_dropout: 0.4
  no_mask_token_prob: 0.4
  emb_dropout: 0.1
  num_tokens: 512
  causal: True
  flash: True



  
  

