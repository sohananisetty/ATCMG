{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8138b8-714c-4bd5-bc6b-97cc9afa7a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e9292e-e925-4197-9b6d-c67ec0534a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e3b77a-d030-46b2-b0cf-8908bb4890fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b4be21-bd73-456d-9c1e-a74aa6f2c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import pack, rearrange, reduce, repeat, unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3eec76-3888-498f-9e2e-65946d093030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.text_encoders import T5Conditioner,MPNETConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a61c29-40c6-421c-8a6c-3ac0c9112abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config from: /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/tmr/tmr.yaml\n",
      "output_dir:  /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/tmr\n",
      "contrastive: 0.1\n",
      "fact: None\n",
      "kl: 1e-05\n",
      "latent: 1e-05\n",
      "recons: 1.0\n",
      "temperature: 0.1\n",
      "threshold_selfsim: 0.8\n",
      "threshold_selfsim_metrics: 0.95\n",
      "vae: True\n",
      "Total training params: 16.13M\n",
      "Total number of motions animation: 120 and texts 120\n",
      "Total number of motions idea400: 10949 and texts 10949\n",
      "Total number of motions animation: 2 and texts 2\n",
      "Total number of motions idea400: 577 and texts 577\n",
      "Total number of motions animation: 1 and texts 1\n",
      "Total number of motions idea400: 2 and texts 2\n",
      "training with training 11069 and test dataset of 579 and render 3 samples\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msohananisetty\u001b[0m (\u001b[33mai-choreo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/coc/scratch/sanisetty3/music_motion/ATCMG/wandb/run-20240407_181420-a5vxfe84\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbumbling-bush-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/ai-choreo/tmr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/ai-choreo/tmr/runs/a5vxfe84\u001b[0m\n",
      "/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/tmr\n",
      "0: model total loss: 0.907, recons: 0.693, kl: 7.36 contrastive: 2.14 latent: 1.33\n",
      "0.9067456126213074 inf\n",
      "0: saving model to /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/tmr/checkpoints\n",
      "validation start\n",
      "  0%|                                                    | 0/73 [00:00<?, ?it/s]/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/transformer.py:384: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      "100%|###########################################| 73/73 [00:04<00:00, 16.42it/s]\n",
      "val/ce_loss tensor(0.1682)\n",
      "200: model total loss: 0.751, recons: 0.534, kl: 7.21 contrastive: 2.17 latent: 1.35\n"
     ]
    }
   ],
   "source": [
    "!python train_tmr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e1f68-ee50-49f6-a0c8-02928fe533e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedbd9a-1684-4f67-aaa2-66660cfea3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0786b50-ecf1-4e97-93fc-40f1a878549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5 = T5Conditioner(\"t5-large\")\n",
    "# sent = \" a man walks forward, to the end of the platform, then turns counterclockwise on his heel, before walking back to his starting point.\"\n",
    "# tokn = t5.tokenize(sent)\n",
    "# embed, msk = t5.get_text_embedding(tokn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7741619d-4368-4673-a08a-dc6ef75792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MPNETConditioner()\n",
    "# sent = \" a man walks forward, to the end of the platform, then turns counterclockwise on his heel, before walking back to his starting point.\"\n",
    "# tokn = mp.tokenize(sent)\n",
    "# embed, msk = mp.get_text_embedding(tokn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f2c18b90-2a69-459b-8947-465e3a26e060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e8a0a-72d5-4ffd-be1e-a30e8cb10d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba97d2-2214-4dc9-a716-c7d5cd0791f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7967e07f-6d65-481c-a0ee-2937b7209891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n",
    "from core.datasets.tmr_dataset import TMRDataset, load_dataset, simple_collate\n",
    "from core import MotionRep, TextRep, AudioRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from configs.config_tmr import get_cfg_defaults\n",
    "from core.models.TMR.tmr import TMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ad421-c9f5-46b8-9812-879ccac41067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6681f-8f41-4f4f-a942-c29baea7eabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4742e48-d708-4488-9394-94b7130673c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmr_cfg = get_cfg_defaults()\n",
    "tmr_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/tmr/tmr.yaml\")\n",
    "tmr_cfg.freeze()\n",
    "dataset_args = tmr_cfg.dataset\n",
    "tmr_parms = tmr_cfg.tmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b957f-4315-45de-ba0e-2870ddc07124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2f864f-15d4-4dcf-8b8d-da939b66c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tmr_parms.pop(\"target\")\n",
    "motion_encoder = instantiate_from_config(tmr_cfg.motion_encoder).to(device)\n",
    "text_encoder = instantiate_from_config(tmr_cfg.text_encoder).to(device)\n",
    "motion_decoder = instantiate_from_config(tmr_cfg.motion_decoder).to(device)\n",
    "tmr = TMR(motion_encoder , text_encoder , motion_decoder , lr = tmr_cfg.train.learning_rate, **tmr_parms).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21716048-3b60-4717-b5d5-f0880baccebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb7234-2882-47ab-bb11-5619e19c1649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed256d-a248-4716-a5e8-9c6524a130d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f2f7c-8cb3-491a-b138-61a6e2c2e871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525e9e9-23b9-47d3-b876-fb8f6f9ab9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6821a6-6b7f-443c-964f-aace12c3acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions idea400: 577 and texts 577\n",
      "Total number of motions animation: 2 and texts 2\n"
     ]
    }
   ],
   "source": [
    "train_ds, sampler_train, weights_train  = load_dataset(dataset_names = [\"idea400\" , \"animation\"] , dataset_args=dataset_args, split = \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c0846-4bdd-4837-b273-f70a12df8631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0425f1-f3a5-4759-bf91-efc58902bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            text_conditioner_name = dataset_args.text_conditioner_name,\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            motion_max_length_s=dataset_args.motion_max_length_s,\n",
    "            fps=30,\n",
    "            # only_motion = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fa2b85e-c70e-4ba9-98f8-f71df0fd8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        4,\n",
    "        sampler=sampler_train,\n",
    "        # shuffle = False,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider),\n",
    "        # drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2a29728-a7fe-43e8-ab2b-63471be5bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in (train_loader):\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48def63b-97b2-4cb6-837d-d4296b1f6e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111553d7-8161-4d98-b73c-0eaa241ec81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = inputs[\"motion\"][0]\n",
    "motion_mask = inputs[\"motion\"][1].to(torch.bool)\n",
    "text = conditions[\"text\"][0]\n",
    "text_mask = conditions[\"text\"][1].to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0266a5ae-a146-45cb-9d00-fdcafd773c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_mask.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae80dab-42b2-49ca-9745-2ab20ad99f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c1721d8-5d4b-422c-9324-4d126d3bfa57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf6846c6-b958-45fe-8e75-08a717c15ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f216fca-1219-47ce-817f-5496e873e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a806869-58a1-4ee3-9a13-1b5227bded8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = mp.tokenize(list(inputs[\"texts\"]))\n",
    "sent_embed, sent_msk = mp.get_text_embedding(tkn)\n",
    "conditions[\"sent_emb\"] = (sent_embed , sent_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4d8b0e6-ea5e-45f0-8ea3-5e04fa6452ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "630efeb2-be7c-4ad3-ac1e-5686e198cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = tmr.compute_loss(inputs[\"motion\"] , conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89e16941-4ab9-4502-8c83-8b4fd929f757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recons': tensor(0.6562, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'kl': tensor(8.7833, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'latent': tensor(1.3628, device='cuda:0', grad_fn=<SmoothL1LossBackward0>),\n",
       " 'contrastive': tensor(1.7467, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'loss': tensor(0.8310, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ca228-3199-4c19-9007-fe08d2c3eba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b775a9-8696-4a45-b850-cb13eb3a02be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34113e14-9675-4914-9443-b0bf5516c4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e46dbbc-b309-4f3a-94f0-79c70fa01102",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_motions, m_latents, m_dists = tmr(inps, mask=motion_mask, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bb6e1-be80-4ce4-b846-26793863e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_motions, t_latents, t_dists = tmr(text_x_dict, mask=text_mask, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dcc3e-dc06-4694-8a6c-759234874651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5249b-4c80-4762-b6fb-e661e6aa6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokn = mp.tokenize(sent)\n",
    "embed, msk = mp.get_text_embedding(tokn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da2656ee-547b-4fad-ab40-63622e13e2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/coc/scratch/sanisetty3/music_motion/ATCMG'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6368d74b-e83a-4201-ba79-aae08c3b82b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0db1e5-536a-4290-a3c2-f974481ea8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c1844-6823-4d4a-9de2-f323f830aecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
