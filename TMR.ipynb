{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c8138b8-714c-4bd5-bc6b-97cc9afa7a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e9292e-e925-4197-9b6d-c67ec0534a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e3b77a-d030-46b2-b0cf-8908bb4890fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b4be21-bd73-456d-9c1e-a74aa6f2c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import pack, rearrange, reduce, repeat, unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d3eec76-3888-498f-9e2e-65946d093030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.text_encoders import T5Conditioner,MPNETConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a61c29-40c6-421c-8a6c-3ac0c9112abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e1f68-ee50-49f6-a0c8-02928fe533e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedbd9a-1684-4f67-aaa2-66660cfea3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0786b50-ecf1-4e97-93fc-40f1a878549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5 = T5Conditioner(\"t5-large\")\n",
    "# sent = \" a man walks forward, to the end of the platform, then turns counterclockwise on his heel, before walking back to his starting point.\"\n",
    "# tokn = t5.tokenize(sent)\n",
    "# embed, msk = t5.get_text_embedding(tokn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7741619d-4368-4673-a08a-dc6ef75792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MPNETConditioner()\n",
    "# sent = \" a man walks forward, to the end of the platform, then turns counterclockwise on his heel, before walking back to his starting point.\"\n",
    "# tokn = mp.tokenize(sent)\n",
    "# embed, msk = mp.get_text_embedding(tokn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f2c18b90-2a69-459b-8947-465e3a26e060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e8a0a-72d5-4ffd-be1e-a30e8cb10d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba97d2-2214-4dc9-a716-c7d5cd0791f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7967e07f-6d65-481c-a0ee-2937b7209891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n",
    "from core.datasets.tmr_dataset import TMRDataset, load_dataset, simple_collate\n",
    "from core import MotionRep, TextRep, AudioRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from configs.config_tmr import get_cfg_defaults\n",
    "from core.models.TMR.tmr import TMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ad421-c9f5-46b8-9812-879ccac41067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6681f-8f41-4f4f-a942-c29baea7eabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4742e48-d708-4488-9394-94b7130673c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmr_cfg = get_cfg_defaults()\n",
    "tmr_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/tmr/tmr.yaml\")\n",
    "tmr_cfg.freeze()\n",
    "dataset_args = tmr_cfg.dataset\n",
    "tmr_parms = tmr_cfg.tmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b957f-4315-45de-ba0e-2870ddc07124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c2f864f-15d4-4dcf-8b8d-da939b66c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tmr_parms.pop(\"target\")\n",
    "motion_encoder = instantiate_from_config(tmr_cfg.motion_encoder).to(device)\n",
    "text_encoder = instantiate_from_config(tmr_cfg.text_encoder).to(device)\n",
    "motion_decoder = instantiate_from_config(tmr_cfg.motion_decoder).to(device)\n",
    "tmr = TMR(motion_encoder , text_encoder , motion_decoder , lr = tmr_cfg.train.learning_rate, **tmr_parms).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21716048-3b60-4717-b5d5-f0880baccebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/tmr/checkpoints/tmr.40000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8fb7234-2882-47ab-bb11-5619e19c1649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmr.load_state_dict(pkg[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed256d-a248-4716-a5e8-9c6524a130d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f2f7c-8cb3-491a-b138-61a6e2c2e871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525e9e9-23b9-47d3-b876-fb8f6f9ab9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6821a6-6b7f-443c-964f-aace12c3acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions idea400: 577 and texts 577\n",
      "Total number of motions animation: 2 and texts 2\n"
     ]
    }
   ],
   "source": [
    "train_ds, sampler_train, weights_train  = load_dataset(dataset_names = [\"idea400\" , \"animation\"] , dataset_args=dataset_args, split = \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c0846-4bdd-4837-b273-f70a12df8631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0425f1-f3a5-4759-bf91-efc58902bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            text_conditioner_name = dataset_args.text_conditioner_name,\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            motion_max_length_s=dataset_args.motion_max_length_s,\n",
    "            fps=30,\n",
    "            # only_motion = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fa2b85e-c70e-4ba9-98f8-f71df0fd8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        4,\n",
    "        sampler=sampler_train,\n",
    "        # shuffle = False,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider),\n",
    "        # drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2a29728-a7fe-43e8-ab2b-63471be5bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in (train_loader):\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48def63b-97b2-4cb6-837d-d4296b1f6e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111553d7-8161-4d98-b73c-0eaa241ec81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = inputs[\"motion\"][0]\n",
    "motion_mask = inputs[\"motion\"][1].to(torch.bool)\n",
    "text = conditions[\"text\"][0]\n",
    "text_mask = conditions[\"text\"][1].to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0266a5ae-a146-45cb-9d00-fdcafd773c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_mask.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aae80dab-42b2-49ca-9745-2ab20ad99f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c1721d8-5d4b-422c-9324-4d126d3bfa57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf6846c6-b958-45fe-8e75-08a717c15ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f216fca-1219-47ce-817f-5496e873e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a806869-58a1-4ee3-9a13-1b5227bded8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = mp.tokenize(list(inputs[\"texts\"]))\n",
    "sent_embed, sent_msk = mp.get_text_embedding(tkn)\n",
    "conditions[\"sent_emb\"] = (sent_embed , sent_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4d8b0e6-ea5e-45f0-8ea3-5e04fa6452ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "630efeb2-be7c-4ad3-ac1e-5686e198cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = tmr.compute_loss(inputs[\"motion\"] , conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89e16941-4ab9-4502-8c83-8b4fd929f757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recons': tensor(0.6562, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'kl': tensor(8.7833, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'latent': tensor(1.3628, device='cuda:0', grad_fn=<SmoothL1LossBackward0>),\n",
       " 'contrastive': tensor(1.7467, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'loss': tensor(0.8310, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ca228-3199-4c19-9007-fe08d2c3eba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b775a9-8696-4a45-b850-cb13eb3a02be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34113e14-9675-4914-9443-b0bf5516c4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e46dbbc-b309-4f3a-94f0-79c70fa01102",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_motions, m_latents, m_dists = tmr(inps, mask=motion_mask, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bb6e1-be80-4ce4-b846-26793863e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_motions, t_latents, t_dists = tmr(text_x_dict, mask=text_mask, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dcc3e-dc06-4694-8a6c-759234874651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5249b-4c80-4762-b6fb-e661e6aa6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokn = mp.tokenize(sent)\n",
    "embed, msk = mp.get_text_embedding(tokn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d388de8-8d9b-46ae-85a0-80ce1c6b87a1",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e87b442-10d3-4d4b-b9d8-b6c330b7b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.TMR.tmr import get_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6368d74b-e83a-4201-ba79-aae08c3b82b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            text_conditioner_name = dataset_args.text_conditioner_name,\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            motion_max_length_s=dataset_args.motion_max_length_s,\n",
    "            fps=30,\n",
    "            # only_motion = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac0db1e5-536a-4290-a3c2-f974481ea8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.base_dataset import BaseMotionDataset\n",
    "base_dset = BaseMotionDataset(motion_rep=MotionRep.BODY , hml_rep= \"gpvc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd602886-407e-4085-a0ad-83859bbc8578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3ba3c-e207-499d-b2ef-ce489761561f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a86c1844-6823-4d4a-9de2-f323f830aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"a man sets to do a backflips then fails back flip and falls to the ground\"\n",
    "mot=\"/srv/hays-lab/scratch/sanisetty3/motionx/motion_data/new_joint_vecs/humanml/001034.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a06df4a-9831-4f7e-be47-07ac7c272b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = np.load(mot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "347af130-3f12-4742-8aea-64fa378b7b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 623)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00413697-fd2b-48d8-93a3-14ac214c0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed, text_mask = condition_provider._get_text_features(\n",
    "        raw_text=text,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "915373ef-6635-4194-901e-a1b69efc496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_motion = base_dset.get_processed_motion(\n",
    "            motion, motion_rep=MotionRep(dataset_args.motion_rep), hml_rep=dataset_args.hml_rep\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d21be686-931f-433d-a64c-1cd38813f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_body = torch.Tensor(processed_motion()).to(device)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e475df51-f2c9-49fa-b0a4-20417e1c5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_x_dict = {\"x\": mot_body, \"mask\": torch.ones_like(mot_body)[...,0].to(torch.bool)}\n",
    "text_x_dict = {\"x\": text_embed, \"mask\": text_mask.to(torch.bool)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea5e880c-d7aa-430e-8f72-08c8c6975fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120, 137])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mot_body.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40016fa8-eea0-4b01-ac82-3bda4cfbf7be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lat_m = tmr.encode(motion_x_dict, sample_mean=True)[0]\n",
    "lat_t = tmr.encode(text_x_dict, sample_mean=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92585c8e-cb80-49b3-bc06-bef76d2a07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = get_score_matrix(lat_t, lat_m).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "283db8e6-553a-4e7e-b07a-5ff2b0dfef76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7725, grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c309f-4946-4bea-a136-0bb5c0dd5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "        # motion -> latent\n",
    "        # motion_x_dict = collate_x_dict([motion_x_dict])\n",
    "        lat_m = tmr.encode(motion_x_dict, sample_mean=True)[0]\n",
    "\n",
    "        # text -> latent\n",
    "        text_x_dict = collate_x_dict(text_model([text]))\n",
    "        lat_t = model.encode(text_x_dict, sample_mean=True)[0]\n",
    "\n",
    "        score = get_score_matrix(lat_t, lat_m).cpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
