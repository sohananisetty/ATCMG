{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231a3e8-9e24-4990-b940-00cdc6b15e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c44eef0-cea4-4ac9-b924-1327280f235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d81025f-b2fd-4067-9c7a-5c21f74f8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d36d72-1eba-4fd0-ba1e-69a4e714339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70de7dab-5b08-4278-872f-ca3885ac3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllFile(base):\n",
    "    file_path = []\n",
    "    for root, ds, fs in os.walk(base, followlinks=True):\n",
    "        for f in fs:\n",
    "            fullname = os.path.join(root, f)\n",
    "            file_path.append(fullname)\n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395afd96-a4f7-45e3-b006-57abc3191800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.motion_processing.hml_process import recover_from_ric, recover_root_rot_pos,recover_from_rot\n",
    "import utils.vis_utils.plot_3d_global as plot_3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis(mot , dset , name = \"motion\"):\n",
    "\n",
    "    if isinstance(mot , torch.Tensor):\n",
    "        mot = dset.toMotion(mot)\n",
    "    mot =dset.inv_transform(mot)\n",
    "\n",
    "\n",
    "\n",
    "    xyz = np.array(dset.to_xyz(mot).cpu())\n",
    "\n",
    "    print(xyz.shape)\n",
    "\n",
    "    \n",
    "    plot_3d.render(xyz , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/{name}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f8324-7df7-471e-9832-56b3e3c4c9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1523299e-4f73-48b0-8e16-03e03464321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_body/vqvae_body.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538bd7db-2d03-44e0-a757-98be718d734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.conditioner import ConditionProvider, ConditionFuser\n",
    "from core.datasets.multimodal_dataset import MotionAudioTextDataset, load_dataset, simple_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbffeb7-ce5f-4ee5-8c9f-280090d0729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.attend import Attention\n",
    "from core import AttentionParams\n",
    "from core import AttentionParams, TranslationTransformerParams, PositionalEmbeddingParams, PositionalEmbeddingType, MotionRep, AudioRep, TextRep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c49f3ff-34de-4ab9-91d2-d7fa22f60310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from core.models.generation.translation_transformer import TranslationTransformer\n",
    "# translation_tranformer = TranslationTransformer(cfg.translation_transformer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c01eae-afd4-40a0-93d5-e157c3f081c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d84de22-8d50-499f-b8c9-4b36fc54b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = cfg.dataset\n",
    "# condition_provider = ConditionProvider(\n",
    "#             motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "#             audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "#             text_rep=TextRep(dataset_args.text_rep),\n",
    "#             motion_padding=dataset_args.motion_padding,\n",
    "#             audio_padding=dataset_args.audio_padding,\n",
    "#             motion_max_length_s=10,\n",
    "#             audio_max_length_s=10,\n",
    "#         )\n",
    "\n",
    "condition_provider2 = ConditionProvider(\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a6c40a-46d6-4224-8264-728c16e98133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.multimodal_dataset import MotionAudioTextDataset\n",
    "from core.datasets.vq_dataset import VQSMPLXMotionDataset\n",
    "from core.datasets.vq_dataset import simple_collate as simple_collate2\n",
    "from core import Motion\n",
    "\n",
    "from utils.motion_processing.skeleton import Skeleton, t2m_kinematic_chain , body_joints_id, t2m_raw_body_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db03f747-24d7-4ef0-81ed-27b999193a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = MotionAudioTextDataset(\"moyo\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"body\" , hml_rep = \"gprvc\", split = \"test\"   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88487a56-d2bf-4be8-a0d3-caa773a012db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions choreomaster: 34\n"
     ]
    }
   ],
   "source": [
    "dset = VQSMPLXMotionDataset(\"choreomaster\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"body\" , hml_rep = \"rv\", split = \"train\" , window_size = 600  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ff16e6-0b76-40f3-a621-22c48e3163ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.motion_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a913b-15de-48f4-8119-a4bd11148db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e823bc41-08e3-4b4d-ae60-923d5e00c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dset,\n",
    "        4,\n",
    "        # sampler=sampler,\n",
    "        collate_fn=partial(simple_collate2 , conditioner = condition_provider2),\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd5510e5-d665-4f72-880c-366803188456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c8bcf1d-cdf8-453e-8d05-4a46cd003c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8479f4b4-20d6-4f36-baf3-4b18bd70e637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c27946fe-185d-4751-9c5e-78b571d0579d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300, 126])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mot = inputs[\"motion\"][0]\n",
    "mot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f71a6d8-ea08-4318-8cef-30bbf340e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.render_hml(mot[0] , \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/r.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983f84f-040c-44a7-8766-e0c06aa3636d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a428a18-0689-422a-ac5c-f0d1f57fbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "hml_rep = dset.hml_rep\n",
    "motion_rep = dset.motion_rep\n",
    "nb_joints = dset.nb_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e79f0-1361-4c1b-b397-a318b153fb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "82c63298-1c34-41e1-bf85-c1d63e635856",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seq = []\n",
    "\n",
    "if \"g\" in hml_rep:\n",
    "    split_seq.append(4)\n",
    "if \"p\" in hml_rep:\n",
    "    if motion_rep == MotionRep.BODY or motion_rep == MotionRep.FULL:\n",
    "        split_seq.append((nb_joints - 1) * 3)\n",
    "    else:\n",
    "        split_seq.append((nb_joints) * 3)\n",
    "if \"r\" in hml_rep:\n",
    "    if motion_rep == MotionRep.BODY or motion_rep == MotionRep.FULL:\n",
    "        split_seq.append((nb_joints - 1) * 6)\n",
    "    else:\n",
    "        split_seq.append((nb_joints) * 6)\n",
    "if \"v\" in hml_rep:\n",
    "    split_seq.append(nb_joints * 3)\n",
    "if \"c\" in hml_rep:\n",
    "    split_seq.append(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e454f2b9-b5d0-4ce6-97d2-dc2ecaf9136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.rotation_conversions as geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4c5113d-a472-49e9-bf82-dc938dfa1906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300, 21, 6])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a11656-f410-40d2-a57e-5af91f621461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4fe1c6c5-2c6b-4c7f-bf0d-e285d2f3068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1200, 21, 3, 3])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry.rotation_6d_to_matrix(mot.view(-1, 21 , 6).contiguous()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e8323-0a3a-462f-a7ad-22116128b288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9328e5dd-ac7b-432b-91b1-2ebe4a9d4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.resnetVQ.vqvae import HumanVQVAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74993259-b07b-4f4d-a975-025467755ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vqvae_args = cfg.vqvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cb567ed-0fdb-4ab4-a87f-4148770c737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_args.nb_joints = dset.nb_joints\n",
    "vqvae_args.motion_dim = dset.motion_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385245a-2583-432d-9766-35a3c6244f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c05c20d6-13b2-486c-8c91-9642fce9b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_model = HumanVQVAE(vqvae_args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "727075fa-2e54-4210-bcfa-1aff2e8b5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.loss import ReConsLoss\n",
    "\n",
    "loss_fnc = ReConsLoss(\"l1_smooth\" , True , vqvae_args.nb_joints , hml_rep=dset.hml_rep , motion_rep = dset.motion_rep  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134c0ac-4415-4764-b0f4-4356dfb2ff47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27936f3d-6689-4a80-b86a-8d009d101b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = inputs[\"motion\"][0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb389fa3-0cfb-4d91-935c-3af122a45568",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vqvae_model(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4bca189-be1c-41c4-bc5e-96f6930d36a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300, 192])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.decoded_motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ff2b2ad-6d96-4c29-8ee2-dd8ecfb57cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fnc(pred.decoded_motion , motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486398a-5a6c-4a0a-a50f-1842abf4892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de676aac-a82e-4380-83d1-592d4022d303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7590eb-21af-415a-9e3e-da25820ea7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b01a49-d07c-4f10-884a-f9a40e900425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca05be39-f683-406e-9089-a7fe5f1ff9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mottt = dset.toMotion(mot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "295dc60c-bb94-46eb-823b-79e3d0a7cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "vis(mot[0] , dset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fcdb4027-1b77-4fe4-ba93-ec3b02fa5c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mot.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe16028-cc0b-4c6c-bb78-e5c4ae548e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a08eab58-a9aa-4b5f-8e8a-8f10b395752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sap = AttentionParams(dim = 256 , causal=True)\n",
    "cap = AttentionParams(dim = 256 , causal=True , add_null_kv=True)\n",
    "transformer_params = TranslationTransformerParams(self_attention_params = sap , \n",
    "                                                  cross_attention_params = cap , \n",
    "                                                  depth = 1, \n",
    "                                                  positional_embedding_params=PositionalEmbeddingParams(dim = 256) , \n",
    "                                                  positional_embedding=PositionalEmbeddingType.SINE,\n",
    "                                                  fuse_method = {\"cross_seperate\" : [\"audio\" , \"text\"]}\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630d974-93d0-4280-95bd-af6608b7c25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f3c933f-45d5-4de5-aaab-f686912b5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.generation.translation_transformer import ClassifierFreeGuidanceDropout, TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e613e4b8-66da-4bb7-8a89-106d7a36c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1872329-3bc6-4747-a07a-a54ec5fc8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = ScaledSinusoidalEmbedding(dim , theta = 10000)\n",
    "cfg_dropout = ClassifierFreeGuidanceDropout(\n",
    "            0.0\n",
    "        )\n",
    "condition_fuser = ConditionFuser({\"cross\" : [\"audio\"] ,   \"prepend\" : [\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1439c147-8bf7-4c09-ae54-17795f37710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_blocks = TransformerBlock(sap , cap).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "015cd7e4-d7de-467f-8456-65a8f8ba8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_audio = (\n",
    "    nn.Linear(128, dim).cuda()\n",
    "    \n",
    ")\n",
    "project_text = (\n",
    "    nn.Linear(768, dim).cuda()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b47af8-bb76-4689-b032-09d84a7a8220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc0e3b0d-adeb-42be-aee0-fd1cd1f965e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = inputs[\"motion\"][0]\n",
    "motion_padding_mask = inputs[\"motion\"][1]\n",
    "device, b, n , d = motion.device, *motion.shape\n",
    "translation = motion[... , :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd467842-783b-4455-88c9-26f56b3fbdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "730ab66a-8964-4d14-96d6-2df66e7593c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (\n",
    "    pos_emb(translation).repeat(b, 1, 1) * motion_padding_mask.unsqueeze(-1),\n",
    "    motion_padding_mask,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5cb0cad0-2af1-4454-9758-0ec68512fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = cfg_dropout(conditions , 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8dd5b0f4-e77e-4756-954d-77ba6601fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed = project_audio(conditions[\"audio\"][0])\n",
    "text_embed = project_text(conditions[\"text\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4a1b86c-ca5f-4ec6-8202-a36d09b844cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[\"audio\"] = (audio_embed, conditions[\"audio\"][1])\n",
    "conditions[\"text\"] = (text_embed, conditions[\"text\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adeb1016-d521-4224-8879-ab3242dc4b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 256])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87c3f075-35d4-4819-89ef-738c2b051860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_, cross_inputs_ = condition_fuser(x, conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a92789-2766-4e23-b541-a038327a87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dbb104dd-82b5-457e-b3ca-e04219a6ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = inputs_[0]\n",
    "x_padding_mask = inputs_[1]\n",
    "context = cross_inputs_[0]\n",
    "context_padding_mask = cross_inputs_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b84ba88-b457-4da0-bca0-82c8fbecea73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 153, 256])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c13288aa-a006-4883-a4e7-9323dc623244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 153])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1271c65-bf6f-4541-aab3-b48d5591a401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 256])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5566d64b-0f3d-426a-950e-85a250755465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34485714-d18d-4554-8c67-372d1e138f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83a0dd4a-b1e7-4a18-a047-ca7e8fd18f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2a134-e513-4b75-9034-45643295e480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36579128-c825-4f7e-9416-b852d8536cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = transformer_blocks(\n",
    "            x=x_,\n",
    "            mask=x_padding_mask,\n",
    "            context=context,\n",
    "            context_mask=context_padding_mask,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "557f7668-0ab2-47de-8f5b-3389a5c0751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embed[:, -n:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2e0c1b4-5cd3-494e-b89e-7cb40efd70fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116, 256])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e4741-b259-4a50-a2ae-4ebf7ac1a649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de48aa-bc99-4d66-921d-da96baa01e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38264d9e-7b0e-450c-a8fd-45464f90a4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16676f3f-c4e0-402e-8192-79b24528c866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f85cfd87-d174-419a-81d7-895447c01313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = ScaledSinusoidalEmbedding(PositionalEmbeddingParams(dim = 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "983afa5c-2dc2-4733-8081-3e7e644bd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b , n , _ = input[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c64a3-ce84-40d1-bbe3-541aa798a582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d934f4b8-0532-4a3f-9382-507fc14f2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = pos_emb(input[\"motion\"][0]).repeat(b , 1 ,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ce8b3c55-1c80-493f-bf3f-d1515d2e4807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116, 256])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb8349-57bd-482e-b00a-36fcc5670155",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, (b , c) in conditions.items():\n",
    "    print(a)\n",
    "    print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a53af4-0e65-4077-a1a2-a19f9cef26c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bb9f8cd0-8e0f-470a-8fc3-c02969b2f06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_ , cross_inputs = condition_fuser(x , conditions  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ee340a5a-6b33-43fc-8e74-e165409b7731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 153, 256])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2a8b199b-04a9-4597-90b0-ed420188c671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 500, 256])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62191059-8fe0-489d-9fd9-04bdc9dd805b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
