{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231a3e8-9e24-4990-b940-00cdc6b15e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c44eef0-cea4-4ac9-b924-1327280f235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d81025f-b2fd-4067-9c7a-5c21f74f8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d36d72-1eba-4fd0-ba1e-69a4e714339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import pack, rearrange, reduce, repeat, unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70de7dab-5b08-4278-872f-ca3885ac3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllFile(base):\n",
    "    file_path = []\n",
    "    for root, ds, fs in os.walk(base, followlinks=True):\n",
    "        for f in fs:\n",
    "            fullname = os.path.join(root, f)\n",
    "            file_path.append(fullname)\n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395afd96-a4f7-45e3-b006-57abc3191800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.motion_processing.hml_process import recover_from_ric, recover_root_rot_pos,recover_from_rot\n",
    "import utils.vis_utils.plot_3d_global as plot_3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis(mot , dset , name = \"motion\"):\n",
    "\n",
    "    if isinstance(mot , torch.Tensor):\n",
    "        mot = dset.toMotion(mot)\n",
    "    mot =dset.inv_transform(mot)\n",
    "\n",
    "\n",
    "\n",
    "    xyz = np.array(dset.to_xyz(mot).cpu())\n",
    "\n",
    "    print(xyz.shape)\n",
    "\n",
    "    \n",
    "    plot_3d.render(xyz , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/{name}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f8324-7df7-471e-9832-56b3e3c4c9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774b40d-c90d-4ec3-a9fa-6c901473eb7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027419bb-c6be-4b00-af51-c9fac0086386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b474f6b-0049-4b20-b32c-1171e3d839f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b77bc2c-04ea-4641-bd04-a0d71d2fa918",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_mots' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m lenss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mall_mots\u001b[49m):\n\u001b[1;32m      3\u001b[0m     lenss\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mload(i)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m7.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_mots' is not defined"
     ]
    }
   ],
   "source": [
    "lenss = []\n",
    "for i in tqdm(all_mots):\n",
    "    lenss.append(np.load(i).shape[-1]/7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93968713-96c2-4f4d-9e3c-fec0bf674553",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(data)\n",
    "std_dev = np.std(data)\n",
    "\n",
    "# Create a range of x values\n",
    "x_values = np.linspace(mean - 3*std_dev, mean + 3*std_dev, 100)\n",
    "\n",
    "# Calculate the probability density function (PDF) of the normal distribution\n",
    "pdf = (1/(std_dev * np.sqrt(2*np.pi))) * np.exp(-0.5*((x_values - mean)/std_dev)**2)\n",
    "\n",
    "# Plot the normal distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, pdf, color='blue', label='Normal Distribution')\n",
    "plt.axvline(mean, color='red', linestyle='--', label='Mean')\n",
    "\n",
    "# Draw standard deviation lines\n",
    "plt.axvline(mean - std_dev, color='green', linestyle='--', label='Mean - 1 Std Dev')\n",
    "plt.axvline(mean + std_dev, color='green', linestyle='--', label='Mean + 1 Std Dev')\n",
    "plt.axvline(mean - 2*std_dev, color='purple', linestyle='--', label='Mean - 2 Std Dev')\n",
    "plt.axvline(mean + 2*std_dev, color='purple', linestyle='--', label='Mean + 2 Std Dev')\n",
    "\n",
    "plt.hist(data, bins=30, density=True, alpha=0.5, color='orange', label='Data Histogram')  # Plot histogram of data for comparison\n",
    "# plt.title('Normal Distribution Plot')\n",
    "# plt.xlabel('Values')\n",
    "# plt.ylabel('Probability Density')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75337e-08df-418c-854d-f0b05e9c9524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gen_cfg = strm_get_cfg_defaults()\n",
    "# gen_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_streaming/motion_streaming.yaml\")\n",
    "# gen_cfg.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d412fc-a32b-413d-8975-bd7300e1f256",
   "metadata": {},
   "source": [
    "## VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba58dbf4-e5be-4e12-a0a7-c0349927c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.resnetVQ.vqvae import HumanVQVAE\n",
    "from configs.config import cfg, get_cfg_defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dfb6d8-fef1-4e6c-8af1-dbe9e8e3b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vqvae(gen_cfg):\n",
    "    \n",
    "    body_cfg = get_cfg_defaults()\n",
    "    body_cfg.merge_from_file(gen_cfg.vqvae.body_config)\n",
    "    left_cfg = get_cfg_defaults()\n",
    "    left_cfg.merge_from_file(gen_cfg.vqvae.left_hand_config)\n",
    "    right_cfg = get_cfg_defaults()\n",
    "    right_cfg.merge_from_file(gen_cfg.vqvae.right_hand_config)\n",
    "    # left_hand_model = HumanVQVAE(left_cfg.vqvae).to(\"cuda\").eval()\n",
    "    # left_hand_model.load(os.path.join(left_cfg.output_dir, \"vqvae_motion.pt\"))\n",
    "    \n",
    "    # right_hand_model = HumanVQVAE(right_cfg.vqvae).to(\"cuda\").eval()\n",
    "    # right_hand_model.load(os.path.join(right_cfg.output_dir, \"vqvae_motion.pt\"))\n",
    "    \n",
    "    body_model = HumanVQVAE(body_cfg.vqvae).to(\"cuda\").eval()\n",
    "    body_model.load(os.path.join(body_cfg.output_dir, \"vqvae_motion.pt\"))\n",
    "\n",
    "    return body_model, body_cfg\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3ff44-3e94-48bb-a0db-f2dd1a0cc536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ed84f-4fb4-4c59-ae89-7e9e6caae0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12a89bfa-687b-44dd-b498-a43e0ef7b816",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Motion Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735ceed-be47-460e-96c0-da344db04f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider, ConditionFuser\n",
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "from core.models.generation.motion_generator import Transformer, MotionMuse\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad8049-a4a0-4612-97ae-06e6e22ffb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_t2m import cfg, get_cfg_defaults\n",
    "from configs.config import get_cfg_defaults as get_cfg_defaults3\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_generation/motion_generation.yaml\")\n",
    "cfg.freeze()\n",
    "mmuse_args = cfg.motion_generator\n",
    "dataset_args = cfg.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c174676-b3a5-424c-a6a7-212b1960263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = mmuse_args.pop(\"target\")\n",
    "motion_muse = MotionMuse(mmuse_args).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441fb76-675e-4500-ab2f-2d528507c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.resnetVQ.vqvae import HumanVQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17fa70-7497-441b-bfc2-6f80c4315101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vcfg = get_cfg_defaults3()\n",
    "vcfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_body_gprvc/vqvae_body_gprvc.yaml\")\n",
    "vqvae_args = vcfg.vqvae\n",
    "vqvae_args.nb_joints = 22\n",
    "vqvae_args.motion_dim = 263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2fcee-d2d4-4428-b66e-da75989882f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153aab1a-472c-4f32-9477-7cef6c60c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.split(np.cusum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb8d3b-a01c-4d29-8c2b-635e1daf80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_model = HumanVQVAE(vqvae_args).to(device).eval()\n",
    "vqvae_model.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACMG/checkpoints/smplx_resnet/vqvae_motion.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ab9d2-a089-48ef-b155-7b58f558ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1f7b4-6181-4bbf-be86-53f21f954486",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=10,\n",
    "            audio_max_length_s=10,\n",
    "            pad_id = motion_muse.transformer.pad_token_id,\n",
    "            fps=30/4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646cf7c-5536-43f8-98dc-335c8791ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bod_ind = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/indices/body/aist/subset_0000/Dance_Break_3_Step_clip_1.npy\")\n",
    "# lh_ind = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/indices/left_hand/aist/subset_0000/Dance_Break_3_Step_clip_1.npy\")\n",
    "# rh_ind = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/indices/right_hand/aist/subset_0000/Dance_Break_3_Step_clip_1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e52a53-c80a-44cc-b2d3-c89a18eb081b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e30407-e8e1-4e05-8fe1-28f95c5eec4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a0df4-f265-41b5-9577-5162b7e262f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4d76d-6cc5-4fe2-bd4b-7b5984f591eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44106b1-f9a2-45cb-9a2e-e20773e110f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "\n",
    "dset = MotionIndicesAudioTextDataset(\"animation\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"full\", split = \"train\" , fps = 30/4  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05f6af-6eec-4961-a203-8e3ec4d07d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpss  = next(iter(dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67996729-7f6f-4f75-a95f-adda0b498f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, sampler_train, weights_train  = load_dataset_gen(dataset_args=dataset_args, split = \"train\" , dataset_names = [\"animation\" , \"choreomaster\" ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dc88a-d090-4ebf-831e-b0054072e83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1d3c1-2084-4c57-bd85-b391f57e418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dset,\n",
    "        4,\n",
    "        # sampler=sampler_train,\n",
    "        # shuffle = False,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider),\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce18ef6b-8c40-4b3e-b4b4-704d756b863d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for inputs, conditions in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08cbf2-99c4-4355-8c0f-e1cb331e32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7693e02-e1e4-4840-b20f-2ab6a0cddd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"motion\"][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a017d85-0ab0-4542-8338-93e66c6efd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22949664-9e06-41e8-9368-c533a5a445a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[\"text\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cb22e-4566-4f10-95a4-d3b6e62d3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions = inputs[\"motion\"][0].squeeze().to(torch.long)\n",
    "motion_mask = inputs[\"motion\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f90a96-5765-4831-a80a-6a4bb12e2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_method = {\"cross\": [\"audio\"], \"prepend\": [\"text\"]}\n",
    "condition_fuser = ConditionFuser(fuse_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41376d0a-fdff-4503-a5fb-38167a369969",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed = self.project_audio(conditions[\"audio\"][0])\n",
    "text_embed = self.project_text(conditions[\"text\"][0])\n",
    "\n",
    "inputs_, cross_inputs = self.condition_fuser(\n",
    "    input,\n",
    "    {\n",
    "        \"text\": (text_embed, conditions[\"text\"][1]),\n",
    "        \"audio\": (audio_embed, conditions[\"audio\"][1]),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c731b-4240-4537-a4b7-0baff3c201e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ed176-a935-4fbd-93d6-b004c5768f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af848aa-93f8-487b-ad27-83c6ea2ec1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4261c42-9d36-49ee-b4de-b47996f33721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da28d2c-8543-4356-8644-37db1a506519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227c9af-4388-4331-b300-38aa8c292b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe478ffa-20be-4503-a905-c3d7e3105b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a196780-a1fe-4c89-bf60-c7ab3b7570c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23380439-deef-4902-9bbe-2febb34cd6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f0adb-e11e-4660-b6b1-1c3f4c35777d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "883ccc94-7e5d-4bfe-b8e0-9d8338450255",
   "metadata": {},
   "source": [
    "## Muse gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de613707-a14b-4aff-a7fb-6544d896f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core import MotionTokenizerParams, pattern_providers\n",
    "\n",
    "from core.param_dataclasses import pattern_providers\n",
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n",
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from core.models.generation.muse import MLMModel, MotionMuse\n",
    "import einops\n",
    "from configs.config_t2m import get_cfg_defaults as muse_get_cfg_defaults\n",
    "\n",
    "from core.datasets.text_encoders import BERTConditioner, ClipConditioner, T5Conditioner, parse_prompt_attention\n",
    "from core.datasets.audio_encoders import EncodecConditioner, LibrosaConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d570e458-7804-480a-8a7e-847094d03cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def bkn_to_motion(codes, dset):\n",
    "        # codes b k n\n",
    "        body_inds = codes[:, 0]\n",
    "    \n",
    "        body_motion = body_model.decode(body_inds[0:1]).detach().cpu()\n",
    "        \n",
    "        body_M = dset.toMotion(\n",
    "            body_motion[0],\n",
    "            motion_rep=MotionRep(body_cfg.dataset.motion_rep),\n",
    "            hml_rep=body_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        \n",
    "\n",
    "        return body_M\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cec5516-e2e6-45a3-84a4-6cec03e0dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds, _, _  = load_dataset_gen(dataset_names = [\"animation\"] , dataset_args=dataset_args, split = \"render\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa4c1e5-0f8c-4ab4-b93e-502756ca765e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tranformer_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m motion_gen \u001b[38;5;241m=\u001b[39m MotionMuse(\u001b[43mtranformer_config\u001b[49m , fuse_config , pattern_config)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# pkg = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse/motion_muse.pt\", map_location=\"cuda\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# motion_gen.load_state_dict(pkg[\"model\"])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tranformer_config' is not defined"
     ]
    }
   ],
   "source": [
    "motion_gen = MotionMuse(tranformer_config , fuse_config , pattern_config).to(device)\n",
    "# pkg = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse/motion_muse.pt\", map_location=\"cuda\")\n",
    "# motion_gen.load_state_dict(pkg[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb1df5-07a4-41bb-9ccd-84fb15a4738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, conditions = condition_provider(raw_audio= None, raw_text=\"a person doing kung fu kick and then jumping\")\n",
    "_, neg_conditions = condition_provider(raw_text=\"\")\n",
    "gen_ids = motion_gen.generate(conditions =conditions, neg_conditions = None, duration_s = 30, temperature = 0.2 ,timesteps=18, cond_scale = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65ec6d-48d5-4d86-97dd-ca6e02475436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c9878-2a8f-4f62-a0cb-498e163864e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "832689e8-645f-4e2a-8fda-b696a57edee2",
   "metadata": {},
   "source": [
    "## MotionMuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c3c301-4a10-40d5-948e-a9c1722e491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import MotionTokenizerParams, pattern_providers\n",
    "\n",
    "from core.param_dataclasses import pattern_providers\n",
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n",
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from core.models.generation.muse import MLMModel, MotionMuse\n",
    "import einops\n",
    "from configs.config_t2m import get_cfg_defaults as muse_get_cfg_defaults\n",
    "from core import MotionTokenizerParams\n",
    "\n",
    "from core.datasets.text_encoders import BERTConditioner, ClipConditioner, T5Conditioner, parse_prompt_attention\n",
    "from core.datasets.audio_encoders import EncodecConditioner, LibrosaConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1e93a9-3d59-43a2-8451-5771be61a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = muse_get_cfg_defaults()\n",
    "gen_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse_constant/motion_muse_constant.yaml\")\n",
    "gen_cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5bcc224-0fd5-47c0-9f2c-6c0a71d6c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "tranformer_config = gen_cfg.motion_generator\n",
    "fuse_config = gen_cfg.fuser\n",
    "pattern_config = gen_cfg.codebooks_pattern\n",
    "dataset_args = gen_cfg.dataset\n",
    "\n",
    "target = tranformer_config.pop(\"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec2ab3b-6017-4e7d-8577-df3316638c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_gen = MotionMuse(tranformer_config , fuse_config , pattern_config).to(device)\n",
    "# pkg = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse_constant/motion_muse.pt\", map_location=\"cuda\")\n",
    "# motion_gen.load_state_dict(pkg[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7467431e-81a5-4182-a054-a390e6aa7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_model, body_cfg = load_vqvae(gen_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "082250ce-8c3b-40a7-acd1-c5db268fb5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            text_conditioner_name = dataset_args.text_conditioner_name,\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=dataset_args.motion_max_length_s,\n",
    "            audio_max_length_s=dataset_args.audio_max_length_s,\n",
    "            pad_id = MotionTokenizerParams(tranformer_config.num_tokens).pad_token_id,\n",
    "            fps=30/4,\n",
    "            # device = \"cpu\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad5de26-b0f3-4d1a-959a-2dd14ba1e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = MotionIndicesAudioTextDataset(\"aist\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,window_size_s=4, motion_rep = \"body\", split = \"render\" , fps = 30/4  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc396b33-2403-413e-b51b-171af29a7e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b02cf3-ddd9-43ba-bcaf-b2ec0ee7a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions animation: 2 and texts 2\n",
      "Total number of motions humanml: 8802 and texts 8802\n",
      "Total number of motions perform: 16 and texts 16\n",
      "Total number of motions GRAB: 67 and texts 67\n",
      "Total number of motions idea400: 577 and texts 577\n",
      "Total number of motions humman: 20 and texts 20\n",
      "Total number of motions beat: 162 and texts 162\n",
      "Total number of motions game_motion: 131 and texts 131\n",
      "Total number of motions music: 148 and texts 148\n",
      "Total number of motions aist: 61 and texts 61\n",
      "Total number of motions fitness: 572 and texts 572\n",
      "Total number of motions moyo: 9 and texts 9\n",
      "Total number of motions choreomaster: 2 and texts 2\n",
      "Total number of motions dance: 7 and texts 7\n",
      "Total number of motions kungfu: 42 and texts 42\n",
      "Total number of motions EgoBody: 49 and texts 49\n",
      "Total number of motions HAA500: 17 and texts 17\n"
     ]
    }
   ],
   "source": [
    "train_ds, sampler_train, weights_train  = load_dataset_gen( dataset_args=dataset_args, split = \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83026f28-7b18-413d-b0fa-da7b0b9dc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        4,\n",
    "        sampler=sampler_train,\n",
    "        # shuffle = False,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider , permute = True),\n",
    "        # drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8b12b3d-eed4-4bc1-b5fb-2893a504af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in (train_loader):\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f49b0f-0414-4b7e-9060-e37fbab45483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e3257fb-6c6b-4f01-b666-27a4d2b41940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83892144-716d-4c5c-80de-bff2c633d4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 30])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dee4d6b-d7f7-4b06-b968-006841a920ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss , logits = motion_gen(inputs[\"motion\"] , conditions, return_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "675307ab-526e-4e8a-86c1-7dbff52e34e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.4513, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0f6eb89-b201-4476-8bec-7f96a9aed2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4240, -0.0268, -0.1519,  ...,  0.4622, -0.7852, -0.2308]],\n",
       "\n",
       "        [[-0.7332,  0.0899, -0.0459,  ..., -0.2908, -0.8034, -0.0928]],\n",
       "\n",
       "        [[-0.3531,  0.2674,  0.0455,  ..., -0.2144,  0.4913, -0.5141]],\n",
       "\n",
       "        [[-0.4248,  0.2670,  0.3974,  ..., -0.1895,  0.2985, -0.4660]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5308bd-8c27-4003-9adc-eb51a6fc1143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5c674-1437-4f6f-a6d9-05f66a31f79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab054b-a216-437f-9655-1af9f85b6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask = inputs[\"motion\"][1]\n",
    "motions_ids = inputs[\"motion\"][0].cuda()\n",
    "B, K, T = motions_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbead25f-851b-4bf9-99bb-515a561128c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2656e53-4be5-4fe2-9ef4-cafe9709b30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48acab27-b494-4432-9330-76f9cfe41d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4991fb6-4d68-4949-bf24-691701ac87d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0717e4b-ecfb-4d7c-9492-43cc2369a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_motion = bkn_to_motion(motions_ids, train_ds.datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfebef-75f2-43f6-b4cf-9a789beb7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.datasets[0].render_hml(\n",
    "                    gt_motion[1].detach().squeeze().cpu(),\n",
    "                    \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/gt_motion_recon.gif\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae877a70-ff5b-4017-b1d4-6c14ca9954dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078f5e0-bf5e-402b-bdbc-4c5faf49d67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad6759d-cc9e-4cf5-8ce0-2febecf98ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29fe7835-0963-46fd-be17-2e6f2b4746d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, conditions = condition_provider(raw_audio= None, raw_text=\"a person doing yoga\")\n",
    "_, neg_conditions = condition_provider(raw_text=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d32a5e9c-4e38-4dfc-a5ad-b8ad05261a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef09f0-5c75-4070-bb44-b23a7c9e967d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdc13298-cfc9-447a-9789-e8d01a4d0f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 53.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gen_ids = motion_gen.generate(conditions = conditions, neg_conditions = None, duration_s = 10, temperature = 0.2 ,timesteps=18, cond_scale = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89416158-cb39-46f4-90b2-3f42b64f7b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dfd4fd3-dc60-494c-b2b9-00979d0bdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, conditions = condition_provider(raw_audio= raw_audio2)\n",
    "gen_motion = bkn_to_motion(gen_ids, train_ds.datasets[0])\n",
    "train_ds.datasets[0].render_hml(\n",
    "                    gen_motion,\n",
    "                    \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/gen_novel.gif\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210bf6d9-5383-4309-b01b-1ca954ba0e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f94269-6b28-4446-b540-2d9a7daebdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57fdaad1-be6d-47be-ae32-82943376f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from core.datasets.text_encoders import ClipConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbde3277-119c-4378-9287-51b367f0c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\" , \"\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e5e4c73-e788-4c8a-a9be-a458d8d987b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipp = ClipConditioner(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c17a175e-ff77-4bce-9dd6-29ee8838e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex2 = clipp.tokenize([\"a diagram\", \"a dog\", \"a cat\" , \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11ce810a-e5a0-4ddf-bba6-a83f27b17c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_features2 = clipp.get_text_embedding(tex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3d55d10-065b-4e6a-adc9-f5a8b48d376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0547, -0.0061,  0.0495,  ..., -0.6638, -0.1281, -0.4950],\n",
       "        [ 0.1447,  0.0225, -0.2909,  ..., -0.4472, -0.3420,  0.1798],\n",
       "        [ 0.1981, -0.2040, -0.1533,  ..., -0.4514, -0.5664,  0.0596],\n",
       "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53853e38-f587-4e5b-9f88-23d227bbf828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0549, -0.0061,  0.0493,  ..., -0.6636, -0.1282, -0.4949],\n",
       "        [ 0.1444,  0.0224, -0.2910,  ..., -0.4465, -0.3411,  0.1802],\n",
       "        [ 0.1985, -0.2037, -0.1533,  ..., -0.4517, -0.5664,  0.0595],\n",
       "        [ 0.1006,  0.2429,  0.1260,  ..., -0.7451,  0.0143,  0.2250]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe60962d-8171-4013-b85d-39453a300014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(text_features[:3].float() , text_features2[0][:3] , rtol = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fd97c-6700-4e7a-8db6-cd7077969172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a3fbbee-f8b8-475f-9506-84dd6760230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_mask_like(shape, prob, device=None):\n",
    "    if prob == 1:\n",
    "        return torch.ones(shape, device=device, dtype=torch.bool)\n",
    "    elif prob == 0:\n",
    "        return torch.zeros(shape, device=device, dtype=torch.bool)\n",
    "    else:\n",
    "        return torch.zeros(shape, device=device).float().uniform_(0, 1) < prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e2506-92f7-4867-bee2-b13ca26cfe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ee394d1-3378-4bfe-90ab-dc1bf9a9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = conditions[\"text\"][0].repeat(4 , 1 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b54f2f3-c608-4f50-9abb-19b911dd7229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 768])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea9d97f5-e896-48ee-b813-0fa57346d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_encoding,_ = clipp.get_text_embedding(\n",
    "                        clipp.tokenize(\"\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b15da5d-6862-401c-a1ff-0632c8e1f6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., -0., -0., 0., -0., 0., 0., -0., 0., -0., 0., 0., -0., -0., -0., -0., -0., 0., 0., -0., -0., -0., 0.,\n",
       "         -0., -0., 0., -0., 0., -0., -0., 0., 0., 0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., -0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., -0., -0., 0., -0., 0., -0., -0., 0., -0., -0., 0., 0.,\n",
       "         0., -0., 0., 0., -0., -0., -0., -0., -0., 0., 0., 0., -0., -0., -0., 0., 0., -0., -0., -0., -0., 0., -0., -0.,\n",
       "         -0., 0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., -0., 0., -0., -0., 0., 0., -0., -0., 0.,\n",
       "         0., 0., -0., -0., 0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., -0., -0., 0., 0., 0.,\n",
       "         0., -0., 0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0., 0., -0., 0., 0.,\n",
       "         -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., 0., -0., -0., 0., 0., 0., 0., -0.,\n",
       "         -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0.,\n",
       "         -0., -0., 0., 0., -0., 0., -0., -0., 0., 0., 0., 0., -0., -0., 0., -0., 0., 0., -0., -0., -0., -0., -0., 0.,\n",
       "         -0., -0., 0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0., -0., 0., 0., 0., -0., 0., 0., -0., -0., -0.,\n",
       "         0., 0., 0., -0., -0., -0., -0., 0., 0., 0., -0., -0., 0., -0., 0., -0., 0., -0., -0., 0., 0., -0., 0., 0.,\n",
       "         -0., -0., -0., 0., 0., 0., 0., 0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., -0., -0., -0., 0., 0., -0.,\n",
       "         0., -0., 0., 0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., -0., -0., 0., -0., 0., 0., -0., -0., -0., 0.,\n",
       "         0., -0., -0., 0., -0., 0., 0., -0., -0., -0., -0., 0., -0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.,\n",
       "         0., -0., -0., -0., -0., -0., 0., 0., -0., -0., 0., 0., -0., -0., 0., 0., -0., 0., 0., 0., 0., -0., 0., -0.,\n",
       "         0., -0., 0., 0., -0., 0., 0., -0., -0., -0., 0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., -0.,\n",
       "         -0., -0., -0., -0., 0., -0., -0., 0., -0., 0., 0., -0., 0., 0., -0., 0., -0., 0., 0., -0., 0., 0., -0., -0.,\n",
       "         -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., -0.,\n",
       "         0., 0., -0., -0., -0., 0., 0., -0., 0., -0., 0., 0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0., -0., -0.,\n",
       "         -0., 0., 0., -0., -0., 0., 0., -0., -0., 0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., 0., -0., -0., 0.,\n",
       "         -0., 0., -0., 0., 0., 0., 0., -0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., -0., 0., 0.,\n",
       "         -0., 0., 0., 0., -0., -0., 0., -0., -0., -0., -0., -0., 0., -0., 0., -0., 0., 0., -0., 0., 0., 0., 0., 0.,\n",
       "         -0., -0., 0., 0., 0., 0., 0., -0., 0., -0., 0., -0., 0., -0., 0., 0., -0., 0., -0., -0., 0., 0., 0., 0.,\n",
       "         0., 0., -0., 0., 0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., 0., 0., 0., -0., 0., 0., -0., 0., -0.,\n",
       "         0., -0., -0., 0., -0., -0., 0., -0., 0., 0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., -0., -0.,\n",
       "         -0., -0., -0., 0., -0., -0., -0., -0., -0., 0., 0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0.,\n",
       "         0., 0., 0., 0., 0., -0., 0., 0., 0., 0., -0., -0., 0., -0., 0., -0., -0., 0., 0., -0., -0., 0., -0., -0.,\n",
       "         0., 0., -0., 0., -0., 0., -0., -0., -0., 0., 0., -0., 0., 0., 0., 0., -0., 0., 0., -0., -0., -0., 0., 0.,\n",
       "         0., 0., -0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., 0., -0., 0., 0., 0., -0., 0.,\n",
       "         -0., 0., 0., 0., 0., 0., -0., -0., 0., -0., 0., 0., -0., -0., -0., 0., 0., -0., 0., -0., 0., 0., 0., 0.,\n",
       "         -0., -0., 0., -0., 0., 0., 0., -0., -0., 0., -0., 0., -0., -0., 0., 0., -0., -0., 0., 0., 0., -0., -0., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a589255-5ba8-4088-837d-cf91adbcd217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea848fa-52b7-4bfb-8b88-beaa57acc991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e381ff-09fa-4955-90e0-8a22a1c520dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403485d8-72b9-44f6-a17c-452d429b189a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a8e7ed-a9d6-4fb5-a45a-187c48ce1f72",
   "metadata": {},
   "source": [
    "## Streaming transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e61c8-9de6-4062-a444-aa0c41b2700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from core.param_dataclasses import pattern_providers\n",
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76b02d-2c79-45aa-a014-dd65ec93cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuserStreamer\n",
    "from core.models.generation.lm import LMModel, MotionGen\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d9572-d125-45c7-9892-9383fefc386f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec2ab9-311e-46a7-ae4c-262399be4c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = strm_get_cfg_defaults()\n",
    "gen_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_streaming/motion_streaming.yaml\")\n",
    "gen_cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7b5a3-d60d-4902-8e47-83797a5ed0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_args = gen_cfg.transformer_lm\n",
    "target = lm_args.pop(\"target\")\n",
    "fuse_config = gen_cfg.fuser\n",
    "pattern_args = gen_cfg.codebooks_pattern\n",
    "dataset_args = gen_cfg.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00544a2c-cf08-4e84-a84a-8313866c9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen= MotionGen(lm_args , fuse_config , pattern_args ).to(device)\n",
    "model_gen = model_gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1c75f-9eec-478b-8655-a031016e326a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3749c8e-0eca-48fd-ba1b-3046cb83b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = pattern_args.pop(\"modeling\")\n",
    "pattern_provider = pattern_providers[modeling](lm_args.n_q, delays = pattern_args.delays , flatten_first = pattern_args.flatten_first , empty_initial = pattern_args.empty_initial )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc42ef-4be4-4bd5-8618-6e6681e52706",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_method = fuse_config.pop(\"fuse_method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604e8ba-0e24-4722-a13e-78409cd89b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_method = {'cross': ['text'], 'input_interpolate': ['audio']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb9d56-c713-404a-85e5-69c9b4b015a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(fuse_method, list):\n",
    "    fuse_method = fuse_method[0]\n",
    "condition_fuser = ConditionFuserStreamer(fuse_method, **fuse_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a3f9f-3461-4c9d-bf4d-236287f1a6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861be10-8c39-4080-a103-855c3483316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LMModel(\n",
    "            pattern_provider=pattern_provider,\n",
    "            fuser=condition_fuser,\n",
    "            **lm_args\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a0493-4f58-478a-a699-02f62d0be73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a49bd9-1160-4181-8512-b6e4b3973a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3493b2d-800b-4c06-a117-c5a81b89ab73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40dde6-abbd-41d5-82ec-2835fc4118e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=10,\n",
    "            audio_max_length_s=10,\n",
    "            pad_id = model_gen.model.pad_token_id,\n",
    "            fps=30/4,\n",
    "            # device = \"cpu\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8d1fa-a114-4d34-9deb-77f40e573f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "# dset = MotionIndicesAudioTextDataset(\"beat\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"full\", split = \"render\" , fps = 30/4  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678ef65-eb0b-4491-b383-3bc9af5a03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, sampler_train, weights_train  = load_dataset_gen(dataset_names = [\"humanml\"] , dataset_args=dataset_args, split = \"test\")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        1,\n",
    "        # sampler=sampler_train,\n",
    "        # shuffle = False,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider , permute = True),\n",
    "        # drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd33baa-e890-42a0-9f5e-2f470b5c9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4620f-c0a6-4d5e-a075-1a097bc2a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.datasets[0].fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52109a38-0e3b-49a5-926b-3cbf7848f7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41369c4f-4407-47a6-a9e2-bc0820798cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe674256-814a-44a7-8d56-bf6b243d2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in train_loader:\n",
    "    input_mask = inputs[\"motion\"][1]\n",
    "    motions_or_ids = inputs[\"motion\"][0]\n",
    "    if motions_or_ids.shape[-1] < 1: \n",
    "        print(input_mask.shape , motions_or_ids.shape )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc814c-aa4f-464e-9d76-471a18a2249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b78ff3-d6c7-423c-b991-8fdeb637d096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ae41f-e73e-4543-814f-a2ce73f0b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask = inputs[\"motion\"][1]\n",
    "motions_or_ids = inputs[\"motion\"][0].cuda()\n",
    "B, K, T = motions_or_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda20bc2-4cce-4928-adbb-e537934504e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions = inputs[\"motion\"][0].squeeze().to(torch.long)\n",
    "motion_mask = inputs[\"motion\"][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72a972-691e-4adb-9975-d9058cef37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a619e0-8c14-4e64-acaa-de047244d59b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b546b-0225-4bf1-a579-af34eba142c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[\"text\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a21a7-3d15-4cc8-8a51-e283c4edc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f4c42-e0fb-4c14-88e6-c3b5998417c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[\"audio\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ea48a-12a1-4728-adfc-a8b9eaaa26f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d8a60-d111-4f5b-8891-43893df1a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = conditions[\"audio\"][0]\n",
    "cond_mask = conditions[\"audio\"][1]\n",
    "cond = einops.rearrange(cond, \"b t d -> b d t\")\n",
    "cond = F.interpolate(cond, size=52)\n",
    "cond_mask = (\n",
    "    F.interpolate(\n",
    "        cond_mask.unsqueeze(1).to(torch.float),\n",
    "        size=52,\n",
    "    )\n",
    "    .squeeze(1)\n",
    "    .to(torch.bool)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cfdddd-0d8b-407e-a539-587692c88ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ae6d7-deb4-4e33-92ac-722d1dfd24ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59afbaa-ec89-469c-9bc6-3ede8e91c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_gen((motions, motion_mask), conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3354d-d97a-4921-a1bc-76a38edfec80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a4e90-37b9-453b-b7d9-7d1ca9fd9e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71844ff0-ff1d-48d4-bac9-693e550e9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B , N , C = conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11627b3c-0670-42d6-8cf7-339080aff996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5963313-f768-4695-b785-db59931e2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.compute_predictions(inputs[\"motion\"] , conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716358b3-c74e-4c13-bf76-7856612b98cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3e160-dc04-412e-a0bc-2365e976cab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f58033-d6e5-435f-9839-e0f2268c8292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e5f84-95e6-45c6-b610-abd08cc6e9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca3cc8-6c4a-4d17-910a-816df4dcdf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f752773-ff68-4d72-84a2-a27a927d5bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bc5ef-1191-49b3-b4fc-2922d6e0578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed = model.project_audio(conditions[\"audio\"][0])\n",
    "text_embed = model.project_text(conditions[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770ec8b-fb3e-4501-b11f-2e6fca2db741",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffb358-c31e-48ac-a229-6bf2d976a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = sum([model.emb[k](motions_or_ids[:, k]) for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981829a-08da-4d6a-ac68-4c9d6ddb40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a5d55-dfb6-4635-a512-09636ab3c613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83474047-5877-4996-aef8-2159b756ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba86e5f-a77f-46df-80dd-49366cec791b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce92be-036b-4aa0-9024-4b90c4c8ca01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f0d70-c2f3-4f7b-bbee-7e97aa6e04d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0a48f7-9970-454d-88d1-23fa31ae2af0",
   "metadata": {},
   "source": [
    "## VIusalise motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f3a6d-60e0-40e7-898a-76d40432de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkn_to_motion(codes, dset):\n",
    "        # codes b k n\n",
    "        body_inds = codes[:, 0]\n",
    "        left_inds = codes[:, 1]\n",
    "        right_inds = codes[:, 2]\n",
    "        body_motion = body_model.decode(body_inds[0:1]).detach().cpu()\n",
    "        left_motion = left_hand_model.decode(left_inds[0:1]).detach().cpu()\n",
    "        right_motion = right_hand_model.decode(right_inds[0:1]).detach().cpu()\n",
    "        body_M = dset.toMotion(\n",
    "            body_motion[0],\n",
    "            motion_rep=MotionRep(body_cfg.dataset.motion_rep),\n",
    "            hml_rep=body_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        left_M = dset.toMotion(\n",
    "            left_motion[0],\n",
    "            motion_rep=MotionRep(left_cfg.dataset.motion_rep),\n",
    "            hml_rep=left_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        right_M = dset.toMotion(\n",
    "            right_motion[0],\n",
    "            motion_rep=MotionRep(right_cfg.dataset.motion_rep),\n",
    "            hml_rep=right_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        full_M = dset.to_full_joint_representation(body_M, left_M, right_M)\n",
    "\n",
    "        return full_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f886f9-98ab-4491-929f-134db0aad9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9a234-a968-4fa1-bee2-cee51940b89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d7c71-1288-41de-b3d6-aec9dadd3454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dset = train_ds.datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726932c6-5d92-4c81-a08a-93ba2dffb1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca365eb-b6bf-430a-a9e0-cf92afe27a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd1a72-b2c5-4bd6-89fa-c9a78c8c7a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c34dc-ddc3-4025-ae66-20e924d1c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_inds = motions_or_ids[:,0]\n",
    "left_inds = motions_or_ids[:,1]\n",
    "right_inds = motions_or_ids[:,2]\n",
    "body_motion = body_model.decode(body_inds[0:1]).detach()\n",
    "left_motion = left_hand_model.decode(left_inds[0:1]).detach()\n",
    "right_motion = right_hand_model.decode(right_inds[0:1]).detach()\n",
    "body_M = dset.toMotion(body_motion[0] , motion_rep = MotionRep(body_cfg.dataset.motion_rep) , hml_rep = body_cfg.dataset.hml_rep , )\n",
    "left_M = dset.toMotion(left_motion[0] , motion_rep = MotionRep(left_cfg.dataset.motion_rep) , hml_rep = left_cfg.dataset.hml_rep , )\n",
    "right_M = dset.toMotion(right_motion[0] , motion_rep = MotionRep(right_cfg.dataset.motion_rep) , hml_rep = right_cfg.dataset.hml_rep , )\n",
    "full_M = dset.to_full_joint_representation(body_M , left_M , right_M )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd6e19-edbf-4b5e-ab64-831f4bc8657c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d957c-d3ec-4451-9610-0dde2e70e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7657d-7d95-4398-9b05-2a84e4f861f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = inputs[\"motion\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b1ef0a-1f26-4a44-8fe3-fd4f6cdaafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_motion = bkn_to_motion(motion, dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4c62e-118a-4095-96c2-8ec42b4ef252",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_motion.velocity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603b399-f3c0-44d5-a131-7016920a7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset.render_hml(gt_motion , \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/full_joined.gif\", from_rotation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d2846-aa37-4914-8fe1-93038119241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95ad50-7c7d-46f2-a12c-97a6970d58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_inds = motions_or_ids[:,0]\n",
    "body_motion = body_model.decode(body_inds[0:1]).detach()\n",
    "body_M = dset.toMotion(body_motion[0] , motion_rep = MotionRep(body_cfg.dataset.motion_rep) , hml_rep = body_cfg.dataset.hml_rep , )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081399a-65ae-4747-a56d-3802a0e6c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in tqdm(train_loader):\n",
    "    # print(inputs[\"names\"][0])\n",
    "    \n",
    "    motion = inputs[\"motion\"][0][...,:300]\n",
    "    gt_motion = bkn_to_motion(motion, dset)\n",
    "    # body_inds = motion[:,0]\n",
    "    # with torch.no_grad():\n",
    "    #     body_motion = body_model.decode(body_inds[0:1]).cpu()\n",
    "    # body_M = dset.toMotion(body_motion[0] , motion_rep = MotionRep(body_cfg.dataset.motion_rep) , hml_rep = body_cfg.dataset.hml_rep , )\n",
    "\n",
    "    dset.render_hml(gt_motion , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/all/{os.path.basename(inputs['names'][0])}.gif\", from_rotation = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06d3ea-6ea0-4aa0-a555-3908fad8c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_M.hml_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973207f-d18e-4d3c-ab30-f42f726d3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "choreo = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/motion_data/new_joint_vecs/choreomaster/1160.npy\")\n",
    "full_og = dset.toMotion(choreo , motion_rep = MotionRep(\"full\") , hml_rep = \"gprvc\" )\n",
    "xyz = dset.to_xyz(full_og, from_rotation=True).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf8a32-a788-4d08-bb6d-1bb311b4f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.vis_utils.plot_3d_global as plot_3d\n",
    "plot_3d.render(\n",
    "            np.array(xyz)[:300],\n",
    "            \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/full_og.gif\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebaf935-e899-4010-9dfb-7c28416c4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "choreo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538193f-c369-4e1b-9d2a-5b4769cdf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_M = dset.inv_transform(full_M)\n",
    "full_M.tensor()\n",
    "full_M.root_params = full_og.root_params[:full_M.rotations.shape[0]]\n",
    "xyz_ = dset.to_xyz(full_M, from_rotation=True).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7585ca9-6488-49a7-8335-8eed85e2ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec94b8-fadc-449c-97b8-4d8a617d3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_3d.render(\n",
    "            np.array(xyz_)[:300],\n",
    "            \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/full_joined.gif\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabe69b-94cd-40fc-bd5f-e53f789116f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27527f-245e-4aa1-b13d-6b2b2bf06849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976409d-c462-4ee2-b659-7f6628691592",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_conditions = model.cfg_dropout(conditions, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f1487-6119-4c26-927a-aa2b00f2885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.compute_predictions(inputs[\"motion\"] , conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e834b-0d15-409b-a3b9-cea2fb0d50a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4568d9-bc05-497c-a1f6-acd5daac1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outt = model.generate(conditions = null_conditions , two_step_cfg =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae0039-4a36-4130-ba7a-7974783611bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c369b-96c3-4378-8464-50e639fb022f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1663e-84b2-4bac-83f2-c77eda12320e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9d584-1d77-4bac-9e50-6dbc8498e50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8470b40-073a-4353-a651-99af8be59f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(10):\n",
    "    outt = model.generate(conditions = conditions , two_step_cfg =True)\n",
    "end = time.time()\n",
    "print('custom attention took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ff337-f1c2-4297-97e2-9a34bee74329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(10):\n",
    "    outt = model.generate(conditions = conditions , two_step_cfg =True)\n",
    "end = time.time()\n",
    "print('custom attention without flash took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b0f52-c008-408c-a191-222399b388f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66e0dc-d743-4da6-afbd-3aacd5d918d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(10):\n",
    "    outt = model.generate(conditions = conditions , two_step_cfg =True)\n",
    "end = time.time()\n",
    "print('torch attention took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00118e07-384d-45b0-b8fc-ecfda0545d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca6fa3-696e-44fa-a980-9d14e1564e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ecdff3-035e-4de1-a9c7-e071841ffc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3f30e-3c3f-4c65-aa53-ffab3f9b032c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09223a9f-75d1-47d0-a5a8-e95f22bafbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f10cf3-7354-41a4-9387-2cbdc6e0311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637bf6a-df0b-4cd8-a5df-93164ea093ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feeba5d-cd88-4da8-b3b1-fa6aa37aed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = cfg_s.transformer_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725d30c-b766-4f13-a77c-c9a6e1a8f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = MotionTokenizerParams(model_cfg.card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de950ca-b389-492b-a5dd-442ffefc7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_q = 3\n",
    "codes = inputs[\"motion\"][0].permute(0,2,1).to(torch.long)\n",
    "code_mask = inputs[\"motion\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b54732-8ba6-4285-9c9f-9b2f438329f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, K, T = codes.shape\n",
    "codes = codes.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e1a5f-4d3b-469a-be18-acdc7d3653d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb884ad-ec84-4b05-8932-c879432c1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = pattern_provider.get_pattern(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a31af-5302-4ac8-b55f-37ce3d633d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2affa79-d5a2-4c1a-a109-c0c1a3fc8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_codes, sequence_indexes, sequence_mask = (\n",
    "            pattern.build_pattern_sequence(\n",
    "                codes,\n",
    "                1025,\n",
    "                keep_only_valid_steps=True,\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69c415-f1c7-4344-bb23-8a71add2b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66154dbc-7ca8-427a-9840-c09f2ea8f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273247a6-8017-423d-8a25-1acd03285ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e134f8e-af23-46e1-80f9-9505d5707e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask = torch.ones_like(sequence_mask).repeat(B , 1 , 1)\n",
    "for i in range(n_q):\n",
    "    new_mask[:,i,i+1:] = code_mask[:,0:T-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dd667-48bf-455c-9ead-a85f92113b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fe530-6f4d-4dd2-8661-c97222c0da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67188e6-85eb-41e4-b513-2cfc605bed54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02a6b4-f643-40ec-931c-27be67587d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_mask = (new_mask.sum(1) == new_mask.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9728a38-64b0-4829-a2a9-de1a394e3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba620f8-607f-4868-87d1-bdbd8bad7a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140792f0-0b9c-435e-88da-375174357c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.audio_encoders import EncodecConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bec8-3c58-4545-9d18-2619f7a4bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list = findAllFile(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afcbc2-375e-4d95-b97a-6ef27a397749",
   "metadata": {},
   "outputs": [],
   "source": [
    "audenc = EncodecConditioner(target_sr = 9600)\n",
    "# audlib = AudioConditionerLibrosa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea049b53-c6df-4606-b859-6f34a96b1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src in tqdm(audio_list):\n",
    "    embs = audenc(audio_list[0])\n",
    "    np.save(src.replace(\"/wav\" , \"/encodec\").replace(\".wav\" , \".npy\") , embs.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c7075-36f4-4f16-a3b5-8f4bcfa86b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746469b-975c-4f4e-a86d-44ea4f646cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = audenc(audio_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793e041-2272-42cd-92a1-7b708300f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c23e5-bbbf-4351-adeb-bc8cb1afe27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/encodec/aist/mBR0.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17c903-36ce-4813-9cb9-152a4981422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = audenc(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/choreomaster/0071.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7f591-a7e0-4722-8dcd-5d1c309e5495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb2 = audlib(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/choreomaster/0071.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a77f68-dd04-467d-8c5c-dc32e5dd48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f8574-6d24-4b59-a0a6-89a98b931161",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e882bae-0397-4dfc-928e-c8b6573bed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/encodec/choreomaster/0071.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f834f-ad5b-4cf5-96b0-255d87859e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
