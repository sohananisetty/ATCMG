{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231a3e8-9e24-4990-b940-00cdc6b15e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c44eef0-cea4-4ac9-b924-1327280f235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d81025f-b2fd-4067-9c7a-5c21f74f8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d36d72-1eba-4fd0-ba1e-69a4e714339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70de7dab-5b08-4278-872f-ca3885ac3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllFile(base):\n",
    "    file_path = []\n",
    "    for root, ds, fs in os.walk(base, followlinks=True):\n",
    "        for f in fs:\n",
    "            fullname = os.path.join(root, f)\n",
    "            file_path.append(fullname)\n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395afd96-a4f7-45e3-b006-57abc3191800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_processing.hml_process import recover_from_ric, recover_root_rot_pos,recover_from_rot\n",
    "import utils.vis_utils.plot_3d_global as plot_3d\n",
    "import matplotlib.pyplot as plt\n",
    "def vis(mot , dset , name = \"motion\", joints = 22 , zero_trans = False):\n",
    "    mot = (\n",
    "                    dset.datasets[0]\n",
    "                    .inv_transform(mot.cpu())\n",
    "                    .squeeze()\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    xyz = np.array(recover_from_ric(mot , joints))\n",
    "\n",
    "    \n",
    "    plot_3d.render(xyz , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACTMG/render/{name}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac22d5-a859-4e99-bd15-e97b89d4c98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014138e6-63d0-4926-9b39-ebfcb776a66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa620c-30b3-414f-8c1d-791ebd547f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f8324-7df7-471e-9832-56b3e3c4c9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1523299e-4f73-48b0-8e16-03e03464321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_t2m import cfg, get_cfg_defaults\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_translation/motion_translation.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538bd7db-2d03-44e0-a757-98be718d734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.conditioner import ConditionProvider, ConditionFuser\n",
    "from core.datasets.multimode_dataset import MotionAudioTextDataset, load_dataset, simple_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdbffeb7-ce5f-4ee5-8c9f-280090d0729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.attend import Attention\n",
    "from core import AttentionParams\n",
    "from core import AttentionParams, TranslationTransformerParams, PositionalEmbeddingParams, PositionalEmbeddingType, MotionRep, AudioRep, TextRep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c49f3ff-34de-4ab9-91d2-d7fa22f60310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from core.models.generation.translation_transformer import TranslationTransformer\n",
    "# translation_tranformer = TranslationTransformer(cfg.translation_transformer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29f7c2b-fdae-4aad-a5e8-e06ce0b04fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_provider.motion_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca836ac1-7db3-4752-84d2-4dfa05d283d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c01eae-afd4-40a0-93d5-e157c3f081c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = cfg.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d84de22-8d50-499f-b8c9-4b36fc54b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=10,\n",
    "            audio_max_length_s=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25a6c40a-46d6-4224-8264-728c16e98133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.multimode_dataset import MotionAudioTextDataset\n",
    "from utils.motion_processing.skeleton import Skeleton, t2m_kinematic_chain , body_joints_id, t2m_raw_body_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db03f747-24d7-4ef0-81ed-27b999193a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions moyo: 9 and texts 9\n"
     ]
    }
   ],
   "source": [
    "dset = MotionAudioTextDataset(\"moyo\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"body\" , hml_rep = \"gprvc\", split = \"test\"   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4827dec-ee3f-4ad9-8c2c-b082d9367654",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fad07af2-1016-4a7d-b61e-ccb9e5d0294e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 63)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"motion\"].positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26fb57f2-68fd-4c5b-a849-dd59ab4b19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mot = sample[\"motion\"][10:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb51aff-2d1c-4dc8-be08-aa5650b2884b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a12781b-2b46-471c-af4d-2f8656c50ae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnew_mot\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotion\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m100\u001b[39m]\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/datasets/motion_class.py:296\u001b[0m, in \u001b[0;36mMotion.__setitem__\u001b[0;34m(self, idx, value)\u001b[0m\n\u001b[1;32m    282\u001b[0m     prm_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    283\u001b[0m         (idx, prm)\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, prm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m prm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     ]\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, prm \u001b[38;5;129;01min\u001b[39;00m prm_indices:\n\u001b[0;32m--> 296\u001b[0m         \u001b[43mprm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value[start:stop:step]\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     prm_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    299\u001b[0m         (idx, prm)\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, prm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m prm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     ]\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 2."
     ]
    }
   ],
   "source": [
    "new_mot[:100] = sample[\"motion\"][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e22ec6-787e-4908-824f-24a77a79a20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15fd664c-d352-461b-8bab-51780aae08e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample[\"motion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "84a0ba32-4a18-4bef-a931-5c44d26da4b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmotion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(sample[\"motion\"].root_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef120da2-dcf9-4cf2-8646-46e3b9fb30b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 45)\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"motion\"].positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20acb6b8-4b97-40f5-86c1-aee9a3e8c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 90)\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"motion\"].rotations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51f4faa9-eb6c-4049-95c0-a5c0d215b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 45)\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"motion\"].velocity.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "483cceef-ef8b-435b-b1a0-33ef48ba0f0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmotion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(sample[\"motion\"].contact.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b807e6-b637-40d9-b296-7873e843dbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd721a1d-d189-47ff-8fdf-e959e43e05ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119cc29-ace7-4748-b2c9-4e4d954adb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823bc41-08e3-4b4d-ae60-923d5e00c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dset,\n",
    "        4,\n",
    "        sampler=sampler,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider),\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5510e5-d665-4f72-880c-366803188456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs , conditions in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7702959b-ece4-49f0-ab7d-3d09379e3bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 768])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "599aa12e-23f5-4bf8-84d7-e3da3bc822b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = list(inputs[\"texts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ab12fd1-0c10-4902-baa1-d80a101cc526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kungfu/subset_0003/Shaolin_Kung_Fu_Wushu_Basic_Tiger_Sword_Training_clip_34',\n",
       "       'kungfu/subset_0001/Dragon_Sword_-_Shaolin_Kung_Fu_Wushu_Da_Mo_Sword_clip_15',\n",
       "       'kungfu/subset_0000/Boxing_Kicking_Jumping_clip_7',\n",
       "       'kungfu/subset_0002/Kung_Fu_Wushu_Butterfly_Kick_Bkick_clip_49'],\n",
       "      dtype='<U75')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fbeb63b-2f89-4431-9c57-79aa66ef1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = inputs[\"motion\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a5202eb-05f3-4e53-9b6b-61312e728c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_ = motion[... , [0,1,2,3,-4,-3,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b43ce2d0-3061-41ed-98f6-f94282b9266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.rand_like(motion_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "325da03d-d11c-4806-a228-f46ed4b9d8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3602, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.mse_loss(motion_[...,:4] , pred[...,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "477ecf99-fd0c-4976-8f35-e80de90fee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5878, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.binary_cross_entropy_with_logits(input = pred[...,-4:] , target = motion_[...,-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccf204df-0bba-4d60-a5e5-28c3fcefd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dcfa5b6-e944-4271-af17-4d949d5e28c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5878, device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll(input = pred[...,-4:] , target = motion_[...,-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87daaffe-287d-4f9d-8c65-911dcc17494f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3771189632.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from utils.motion_processing.skeleton import Skeleton, t2m_kinematic_chain, t2m_raw_offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f4ee486-6d83-4f8b-a3bc-7c7372a0e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_raw_offsets = torch.from_numpy(t2m_raw_offsets)\n",
    "kinematic_chain = t2m_kinematic_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32d8d30e-c75e-43e7-9592-9fb0e2ab4353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/coc/scratch/sanisetty3/music_motion/ACMG'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8652eaa-fb12-4636-bdf0-84a1b920bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/coc/scratch/sanisetty3/smplx2hml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /srv/hays-lab/scratch/sanisetty3/smplx2hml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a54eca-b44a-47ae-a971-7bc683c00892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from motion_representation import motionx2positions, body_joints_id, hand_joints_id, n_raw_offsets, kinematic_chain\n",
    "from paramUtil import t2m_kinematic_chain, t2m_raw_body_offsets\n",
    "from common.skeleton import Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "130e2d81-f8d5-4da6-9eca-fb5d7f1b271a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2m_raw_body_offsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7094f5f3-b0fa-46c0-aabf-2e67b12eaecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_joints_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "620e6c5c-65a6-44ad-95df-cf7815cfd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = np.array(\n",
    "        motionx2positions(\n",
    "            \"/srv/hays-lab/scratch/sanisetty3/motionx/motion_data/smplx_322/humanml/000021.npy\"\n",
    "        )\n",
    "    )\n",
    "example_data = example_data.reshape(len(example_data), -1, 3)\n",
    "example_data = torch.from_numpy(example_data)[:, body_joints_id, :]\n",
    "\n",
    "tgt_skel = Skeleton(torch.Tensor(t2m_raw_body_offsets), t2m_kinematic_chain, \"cpu\")\n",
    "tgt_offsets = tgt_skel.get_offsets_joints(example_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6512cf39-da5f-49c9-9892-423d987294a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 52, 3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACMG/core/datasets/data/000021_pos.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b79244b-9611-4535-b9e9-7c2a230cb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACMG/core/datasets/000021_pos.npy\" , example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a33c8416-6d42-40b7-8aff-a375d3ff1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/motion_data/new_joint_vecs/idea400/subset_0000/Row_A_Boat_And_Walking_At_The_Same_Time.npy\")\n",
    "# xyz = np.array(recover_from_ric(torch.Tensor(mot) , 22))\n",
    "# plot_3d.render(xyz , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACMG/render/og.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1d9a92f-1830-4f03-8613-18865c958e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot[: , [1,2,3]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275b0bb-4f5b-4729-a633-860076e2d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = np.array(recover_from_ric(torch.Tensor(mot) , 22))\n",
    "plot_3d.render(xyz , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACMG/render/trans0.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8af35613-0370-4395-8df1-8f5a6c4db9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = np.array(recover_from_rot(torch.Tensor(mot) , 22 , tgt_skel))\n",
    "plot_3d.render(xyz , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACMG/render/trans0rot.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a74ea218-4fe4-469d-8d12-26e86b52fc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 623)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87dcccd7-d3ad-46dc-b447-3194e962dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_num = 52\n",
    "body_joints=22\n",
    "hand_joints=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47927129-6f1e-42fd-abe3-20b28f77e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.cumsum([4 , (joint_num - 1)*3 , (joint_num - 1)*6 , joint_num*3 , 4  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5bf16e13-49df-4ae9-ba2e-5cea85abcd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1., 2.]),\n",
       " array([3., 4.]),\n",
       " array([5.]),\n",
       " array([6., 7.]),\n",
       " array([], dtype=float64)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(8.0)\n",
    "np.split(x, [3, 5, 6, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3a31e-f42b-4d85-a62e-d26dc99f643f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "111c1d15-a63c-414c-b4d4-b56007d3ccb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_params , pos_data , rot_data , vel_data , foot_contact = np.split(mot , aa , -1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "040258ed-4b9d-4204-a6f1-6315ed5b82dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(pos_data , np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34fcf9ee-b71e-42e5-ad1f-f5d5895c920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_pos , hand_pos = np.split(pos_data , np.cumsum([(body_joints-1)*3 , hand_joints*3]) , -1)[:-1]\n",
    "body_rot , hand_rot = np.split(rot_data , np.cumsum([(body_joints-1)*6 , hand_joints*6]) , -1)[:-1]\n",
    "body_vel , hand_vel = np.split(vel_data , np.cumsum([(body_joints)*3 , hand_joints*3]) , -1)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6ea84-d001-4d41-a4ec-57c44eaa19e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d644d80-f42e-4323-a393-2903d5a63833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MotionRep(Enum):\n",
    "    FULL = \"full\"\n",
    "    BODY = \"body\"\n",
    "    HAND = \"hand\"\n",
    "    LEFT_HAND = \"left_hand\"\n",
    "    RIGHT_HAND = \"right_hand\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98cc76a4-a655-47d7-9ce0-df2ae4b72f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'full'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MotionRep.FULL.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "520f8de1-45bb-49de-af0f-08e26806cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e11f583c-e936-4022-8a2e-b7b251222df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Motion:\n",
    "    motion_rep = \"full\"\n",
    "    hml_rep: str = \"gprvc\"\n",
    "    root_params= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57661a00-761c-4f8e-82d1-6de7eba2cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot = Motion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7a35d-5a7f-48b2-b95c-d228af4da42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot.getat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2945e-93e2-4019-825e-63edee94e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(torch.Tensor(body_params) , dset , name = \"og_motion\" , joints = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01317203-9dde-449a-b57f-cfe34a750f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05be39-f683-406e-9089-a7fe5f1ff9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c7e61-cff3-4c60-82cb-b5e6c3fcc0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcdb4027-1b77-4fe4-ba93-ec3b02fa5c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a2f43-dc22-402a-9518-9f8d8f2c60ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e57dd5-ee04-47fd-b0f0-54728cdc05d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d90fb-5f12-41d8-9da2-771daa829ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b167bb-6b57-41c4-b15e-0f1a6f456c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3b42b-d139-4e17-a526-57f19ec3b3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28f55f38-81f8-40a3-86c8-2b3d38d1662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# body_params = dset.datasets[0].transform(body_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5a7f47c-4970-4c01-9112-7e403da167a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 263)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "436d40b8-d129-4d7f-8a03-915cf2236266",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_translation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m motion \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotion\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m      2\u001b[0m pred_motion \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmotion\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m----> 3\u001b[0m pred_motion[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpred_translation\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_translation' is not defined"
     ]
    }
   ],
   "source": [
    "motion = inputs[\"motion\"][0].clone()\n",
    "pred_motion = inputs[\"motion\"][0].clone()\n",
    "pred_motion[..., :4] = pred_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3b5d444-013e-4a09-9b23-e003e281862a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = inputs[\"motion\"][1]\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7b28fe7-a651-45f8-bee1-05b3415a8eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116, 263])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec40451-8298-4316-a727-5fb5d91c6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mott = next(iter(dset.datasets[0]))[\"motion\"]\n",
    "# mott2 = next(next(iter(dset.datasets[0])))[\"motion\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3eb2d710-863a-4b45-b855-8dc3a07bcc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "inp, cnd = condition_provider(\n",
    "            raw_motion=[mott , mott],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21a2cc34-d727-4c28-97ac-90abb0279dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 116, 263])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "190147c2-6906-4293-a7e5-a16f22266e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aa6ab-75ee-4e24-923b-5439b95c66f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509efe0-9faf-4d30-95bf-a5ffefe34081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cafaaa-85e8-408e-9af8-bed59fc83d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b02646d-f69d-4bea-80cf-5dd7353440a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(torch.Tensor(motion[0].detach().cpu()) , dset , name = \"og_motion\" , joints = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb93e0e5-460e-4c2a-b9b4-72e587b5bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(torch.Tensor(pred_motion[0][:sum(mask[0])].detach().cpu()) , dset , name = \"pred_motion\" , joints = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cedce81-51ab-4ea2-860b-56f639968afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(torch.Tensor(body_params) , dset , name = \"og_og_motion\" , joints = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68bb16-1eea-4dfe-892b-c8ed26e90d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39ff4628-cb7e-4238-8eb7-2fa772d0adbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2aed9b3-8a8a-45f6-9654-4b87826a6e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 263)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mott.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ccaa2db-0195-4017-a84f-8163093e4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(torch.Tensor(mott) , dset , name = \"dset_motion\" , joints = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe16028-cc0b-4c6c-bb78-e5c4ae548e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a08eab58-a9aa-4b5f-8e8a-8f10b395752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sap = AttentionParams(dim = 256 , causal=True)\n",
    "cap = AttentionParams(dim = 256 , causal=True , add_null_kv=True)\n",
    "transformer_params = TranslationTransformerParams(self_attention_params = sap , \n",
    "                                                  cross_attention_params = cap , \n",
    "                                                  depth = 1, \n",
    "                                                  positional_embedding_params=PositionalEmbeddingParams(dim = 256) , \n",
    "                                                  positional_embedding=PositionalEmbeddingType.SINE,\n",
    "                                                  fuse_method = {\"cross_seperate\" : [\"audio\" , \"text\"]}\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630d974-93d0-4280-95bd-af6608b7c25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f3c933f-45d5-4de5-aaab-f686912b5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.generation.translation_transformer import ClassifierFreeGuidanceDropout, TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e613e4b8-66da-4bb7-8a89-106d7a36c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1872329-3bc6-4747-a07a-a54ec5fc8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = ScaledSinusoidalEmbedding(dim , theta = 10000)\n",
    "cfg_dropout = ClassifierFreeGuidanceDropout(\n",
    "            0.0\n",
    "        )\n",
    "condition_fuser = ConditionFuser({\"cross\" : [\"audio\"] ,   \"prepend\" : [\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1439c147-8bf7-4c09-ae54-17795f37710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_blocks = TransformerBlock(sap , cap).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "015cd7e4-d7de-467f-8456-65a8f8ba8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_audio = (\n",
    "    nn.Linear(128, dim).cuda()\n",
    "    \n",
    ")\n",
    "project_text = (\n",
    "    nn.Linear(768, dim).cuda()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b47af8-bb76-4689-b032-09d84a7a8220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc0e3b0d-adeb-42be-aee0-fd1cd1f965e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = inputs[\"motion\"][0]\n",
    "motion_padding_mask = inputs[\"motion\"][1]\n",
    "device, b, n , d = motion.device, *motion.shape\n",
    "translation = motion[... , :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd467842-783b-4455-88c9-26f56b3fbdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "730ab66a-8964-4d14-96d6-2df66e7593c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (\n",
    "    pos_emb(translation).repeat(b, 1, 1) * motion_padding_mask.unsqueeze(-1),\n",
    "    motion_padding_mask,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5cb0cad0-2af1-4454-9758-0ec68512fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = cfg_dropout(conditions , 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8dd5b0f4-e77e-4756-954d-77ba6601fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed = project_audio(conditions[\"audio\"][0])\n",
    "text_embed = project_text(conditions[\"text\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4a1b86c-ca5f-4ec6-8202-a36d09b844cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[\"audio\"] = (audio_embed, conditions[\"audio\"][1])\n",
    "conditions[\"text\"] = (text_embed, conditions[\"text\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adeb1016-d521-4224-8879-ab3242dc4b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 256])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87c3f075-35d4-4819-89ef-738c2b051860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_, cross_inputs_ = condition_fuser(x, conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a92789-2766-4e23-b541-a038327a87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dbb104dd-82b5-457e-b3ca-e04219a6ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = inputs_[0]\n",
    "x_padding_mask = inputs_[1]\n",
    "context = cross_inputs_[0]\n",
    "context_padding_mask = cross_inputs_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b84ba88-b457-4da0-bca0-82c8fbecea73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 153, 256])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c13288aa-a006-4883-a4e7-9323dc623244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 153])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1271c65-bf6f-4541-aab3-b48d5591a401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 256])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5566d64b-0f3d-426a-950e-85a250755465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34485714-d18d-4554-8c67-372d1e138f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83a0dd4a-b1e7-4a18-a047-ca7e8fd18f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2a134-e513-4b75-9034-45643295e480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36579128-c825-4f7e-9416-b852d8536cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = transformer_blocks(\n",
    "            x=x_,\n",
    "            mask=x_padding_mask,\n",
    "            context=context,\n",
    "            context_mask=context_padding_mask,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "557f7668-0ab2-47de-8f5b-3389a5c0751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embed[:, -n:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2e0c1b4-5cd3-494e-b89e-7cb40efd70fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116, 256])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e4741-b259-4a50-a2ae-4ebf7ac1a649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de48aa-bc99-4d66-921d-da96baa01e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38264d9e-7b0e-450c-a8fd-45464f90a4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16676f3f-c4e0-402e-8192-79b24528c866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4484c6d1-6c53-499e-8747-585474260881",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7adfa310-1670-4a6a-8799-527ae0440552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.attend import Attention\n",
    "from core.models.dataclasses import AttentionParams, TransformerParams, PositionalEmbeddingParams, PositionalEmbeddingType\n",
    "from core.models.utils import get_obj_from_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "72e627c3-4063-42af-a825-f9d5a31f7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.dataclasses import AttentionParams, TransformerParams, PositionalEmbeddingParams, PositionalEmbeddingType\n",
    "\n",
    "sap = AttentionParams(dim = 256 , causal=True)\n",
    "cap = AttentionParams(dim = 256 , causal=True , add_null_kv=True)\n",
    "transformer_params = TransformerParams(attention_params = sap , cross_attention_params = cap , positional_embedding_params=PositionalEmbeddingParams(dim = 256) , positional_embedding=PositionalEmbeddingType.SINE )\n",
    "transformer_params.depth = 4\n",
    "transformer_params.dim_out = 4\n",
    "transformer_params.audio_input_dim = 128\n",
    "transformer_params.text_input_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1769963c-498f-40af-9d85-82204721349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_audio = nn.Linear(128 , 256).cuda()\n",
    "project_text = nn.Linear(768 , 256).cuda()\n",
    "aud = project_audio(conditions[\"audio\"][0])\n",
    "txt = project_text(conditions[\"text\"][0])\n",
    "conditions[\"audio\"] = (aud , conditions[\"audio\"][1])\n",
    "conditions[\"text\"] = (txt , conditions[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f85cfd87-d174-419a-81d7-895447c01313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = ScaledSinusoidalEmbedding(PositionalEmbeddingParams(dim = 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "983afa5c-2dc2-4733-8081-3e7e644bd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b , n , _ = input[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c64a3-ce84-40d1-bbe3-541aa798a582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d934f4b8-0532-4a3f-9382-507fc14f2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = pos_emb(input[\"motion\"][0]).repeat(b , 1 ,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ce8b3c55-1c80-493f-bf3f-d1515d2e4807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116, 256])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb8349-57bd-482e-b00a-36fcc5670155",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, (b , c) in conditions.items():\n",
    "    print(a)\n",
    "    print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a53af4-0e65-4077-a1a2-a19f9cef26c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bb9f8cd0-8e0f-470a-8fc3-c02969b2f06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_ , cross_inputs = condition_fuser(x , conditions  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ee340a5a-6b33-43fc-8e74-e165409b7731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 153, 256])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2a8b199b-04a9-4597-90b0-ed420188c671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 500, 256])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62191059-8fe0-489d-9fd9-04bdc9dd805b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
