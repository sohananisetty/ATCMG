{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231a3e8-9e24-4990-b940-00cdc6b15e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c44eef0-cea4-4ac9-b924-1327280f235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d81025f-b2fd-4067-9c7a-5c21f74f8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d36d72-1eba-4fd0-ba1e-69a4e714339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import pack, rearrange, reduce, repeat, unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70de7dab-5b08-4278-872f-ca3885ac3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllFile(base):\n",
    "    file_path = []\n",
    "    for root, ds, fs in os.walk(base, followlinks=True):\n",
    "        for f in fs:\n",
    "            fullname = os.path.join(root, f)\n",
    "            file_path.append(fullname)\n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395afd96-a4f7-45e3-b006-57abc3191800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.motion_processing.hml_process import recover_from_ric, recover_root_rot_pos,recover_from_rot\n",
    "import utils.vis_utils.plot_3d_global as plot_3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis(mot , dset , name = \"motion\"):\n",
    "\n",
    "    if isinstance(mot , torch.Tensor):\n",
    "        mot = dset.toMotion(mot)\n",
    "    mot =dset.inv_transform(mot)\n",
    "\n",
    "\n",
    "\n",
    "    xyz = np.array(dset.to_xyz(mot).cpu())\n",
    "\n",
    "    print(xyz.shape)\n",
    "\n",
    "    \n",
    "    plot_3d.render(xyz , f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/{name}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f8324-7df7-471e-9832-56b3e3c4c9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774b40d-c90d-4ec3-a9fa-6c901473eb7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac75337e-08df-418c-854d-f0b05e9c9524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39d412fc-a32b-413d-8975-bd7300e1f256",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1523299e-4f73-48b0-8e16-03e03464321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "\n",
    "vcfg = get_cfg_defaults()\n",
    "vcfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_rv/vqvae_rv.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538bd7db-2d03-44e0-a757-98be718d734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.conditioner import ConditionProvider, ConditionFuser\n",
    "from core.datasets.multimodal_dataset import MotionAudioTextDataset, load_dataset, simple_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbffeb7-ce5f-4ee5-8c9f-280090d0729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.attend import Attention\n",
    "from core import AttentionParams\n",
    "from core import AttentionParams, TranslationTransformerParams, PositionalEmbeddingParams, PositionalEmbeddingType, MotionRep, AudioRep, TextRep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49f3ff-34de-4ab9-91d2-d7fa22f60310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c01eae-afd4-40a0-93d5-e157c3f081c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d84de22-8d50-499f-b8c9-4b36fc54b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.conditioner import ConditionProvider, ConditionFuser\n",
    "# from core.datasets.multimodal_dataset import MotionAudioTextDataset, load_dataset, simple_collate\n",
    "dataset_args = vcfg.dataset\n",
    "\n",
    "\n",
    "condition_provider2 = ConditionProvider(\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a6c40a-46d6-4224-8264-728c16e98133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.multimodal_dataset import MotionAudioTextDataset\n",
    "from core.datasets.vq_dataset import VQSMPLXMotionDataset\n",
    "from core.datasets.vq_dataset import load_dataset, simple_collate as simple_collate2\n",
    "from core import Motion\n",
    "from core.models.resnetVQ.vqvae import HumanVQVAE\n",
    "from core.models.loss import ReConsLoss\n",
    "from utils.motion_processing.skeleton import Skeleton, t2m_kinematic_chain , body_joints_id, t2m_raw_body_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db03f747-24d7-4ef0-81ed-27b999193a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = MotionAudioTextDataset(\"moyo\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"body\" , hml_rep = \"gprvc\", split = \"test\"   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88487a56-d2bf-4be8-a0d3-caa773a012db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions choreomaster: 34\n"
     ]
    }
   ],
   "source": [
    "dset = VQSMPLXMotionDataset(\"choreomaster\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"body\" , hml_rep = \"rv\", split = \"train\" , window_size = 600  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ff16e6-0b76-40f3-a621-22c48e3163ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions animation: 2\n",
      "Total number of motions humanml: 2944\n",
      "Total number of motions perform: 16\n",
      "Total number of motions GRAB: 67\n",
      "Total number of motions idea400: 577\n",
      "Total number of motions humman: 19\n",
      "Total number of motions beat: 162\n",
      "Total number of motions game_motion: 130\n",
      "Total number of motions music: 148\n",
      "Total number of motions aist: 61\n",
      "Total number of motions fitness: 572\n",
      "Total number of motions moyo: 9\n",
      "Total number of motions choreomaster: 2\n",
      "Total number of motions dance: 7\n",
      "Total number of motions kungfu: 42\n",
      "Total number of motions EgoBody: 49\n",
      "Total number of motions HAA500: 17\n"
     ]
    }
   ],
   "source": [
    "test_ds, _, _ = load_dataset(\n",
    "            dataset_args=dataset_args,\n",
    "            split=\"test\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a913b-15de-48f4-8119-a4bd11148db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e823bc41-08e3-4b4d-ae60-923d5e00c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        test_ds,\n",
    "        100,\n",
    "        # sampler=sampler,\n",
    "        collate_fn=partial(simple_collate2 , conditioner = condition_provider2),\n",
    "        # drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5510e5-d665-4f72-880c-366803188456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27946fe-185d-4751-9c5e-78b571d0579d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f71a6d8-ea08-4318-8cef-30bbf340e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.render_hml(mot[0] , \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/r.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638cad6-4505-4f8d-ba5a-294fbf856d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b6be4e-9a49-4954-8feb-13f372ede150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ddacf-ce33-4659-a81a-56d068438e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74993259-b07b-4f4d-a975-025467755ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb567ed-0fdb-4ab4-a87f-4148770c737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_args = vcfg.vqvae\n",
    "vqvae_args.nb_joints = test_ds.datasets[0].nb_joints\n",
    "vqvae_args.motion_dim = test_ds.datasets[0].motion_dim\n",
    "hml_rep = test_ds.datasets[0].hml_rep\n",
    "motion_rep = test_ds.datasets[0].motion_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae23d8b-e76f-4860-adde-179372768976",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_args = vcfg.vqvae\n",
    "vqvae_args.nb_joints = 22\n",
    "vqvae_args.motion_dim = 192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c385245a-2583-432d-9766-35a3c6244f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loss_fnc = ReConsLoss(\"l1_smooth\" , True , vqvae_args.nb_joints , hml_rep=hml_rep , motion_rep = motion_rep  )\n",
    "# loss_fnc2 = ReConsLoss(\"l1_smooth\" , False , vqvae_args.nb_joints , hml_rep=hml_rep , motion_rep = motion_rep  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c5d440-6e7b-45e6-96af-4c4c5efaf38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'target': 'core.models.resnetVQ.vqvae.HumanVQVAE2', 'nb_joints': 22, 'motion_dim': 192, 'dim': 768, 'depth': 6, 'dropout': 0.1, 'down_sampling_ratio': 4, 'conv_kernel_size': 5, 'rearrange_output': False, 'heads': 8, 'codebook_dim': 512, 'codebook_size': 1024, 'num_quantizers': 2, 'quantize_dropout_prob': 0.2, 'shared_codebook': False, 'sample_codebook_temp': 0.4, 'commit': 0.25, 'loss_vel': 1.0, 'loss_motion': 2.0, 'recons_loss': 'l1_smooth', 'use_geodesic_loss': False})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqvae_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "551ebd2e-ff11-41a1-980b-ae09617ac6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync is turned on False\n"
     ]
    }
   ],
   "source": [
    "from core.models.resnetVQ.vqvae import HumanVQVAE2\n",
    "vqvae_model = HumanVQVAE2(vqvae_args).to(device)\n",
    "# vqvae_model.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_rv/vqvae_motion.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0992432-a6d5-45a1-ab52-a473ef28fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.resnetVQ.vqvae import HumanVQVAE\n",
    "vqvae_model = HumanVQVAE(vqvae_args).to(device)\n",
    "# vqvae_model.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_body/vqvae_motion_rv.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d6849bd-255a-4458-ac12-f0c62ac7f392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqvae_model.vqvae.quantizer.codebook.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840b98b-ce1b-47b0-906c-9d585163c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c05c20d6-13b2-486c-8c91-9642fce9b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 512])\n",
      "torch.Size([1250, 512])\n"
     ]
    }
   ],
   "source": [
    "out = vqvae_model(\n",
    "            motion=torch.randn((10 , 100 , 192)).to(device),\n",
    "            # mask=mask,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d09da9-1793-4fea-954f-e7c737eb7c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b10571-f643-44d9-bfaf-17a3bb431560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3e99254-2b8b-4a47-a244-3ebf4af4a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_motion = loss_fnc(\n",
    "            out.decoded_motion, gt_motion, mask=None\n",
    "        )\n",
    "\n",
    "loss_motion2 = loss_fnc2(\n",
    "            out.decoded_motion, gt_motion, mask=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7b546-f0ed-43e3-bd02-be45636cd796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee4d92a8-8311-4634-8c11-780f8f14b25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                       | 1/49 [00:00<00:10,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(289.9571, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                     | 2/49 [00:00<00:10,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(287.7314, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▍                                                                                   | 3/49 [00:00<00:09,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(316.6711, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                 | 4/49 [00:00<00:09,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(343.8243, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                                | 5/49 [00:01<00:09,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(271.9930, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▉                                                                              | 6/49 [00:01<00:08,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(307.7598, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▋                                                                            | 7/49 [00:01<00:08,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(312.7512, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▌                                                                          | 8/49 [00:01<00:08,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(291.0934, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▎                                                                        | 9/49 [00:01<00:08,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(305.5509, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▉                                                                      | 10/49 [00:02<00:07,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(321.3210, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▊                                                                    | 11/49 [00:02<00:07,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(278.0258, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▌                                                                  | 12/49 [00:02<00:07,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(326.5566, device='cuda:0')\n",
      "tensor(301.1002, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▏                                                              | 14/49 [00:02<00:07,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(310.6176, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▉                                                             | 15/49 [00:03<00:06,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(302.9529, device='cuda:0')\n",
      "tensor(302.5337, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▌                                                         | 17/49 [00:03<00:06,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(289.6815, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▎                                                       | 18/49 [00:03<00:06,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(303.2496, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████                                                      | 19/49 [00:03<00:06,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(319.4746, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▉                                                    | 20/49 [00:04<00:05,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(300.9641, device='cuda:0')\n",
      "tensor(295.6805, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▌                                                | 22/49 [00:04<00:05,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(330.6924, device='cuda:0')\n",
      "tensor(261.9393, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████                                             | 24/49 [00:04<00:05,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(319.2980, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████▉                                           | 25/49 [00:05<00:04,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(270.3061, device='cuda:0')\n",
      "tensor(312.0115, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████████▍                                       | 27/49 [00:05<00:04,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(293.3038, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████▎                                     | 28/49 [00:05<00:04,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(318.7498, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████████████                                    | 29/49 [00:05<00:04,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(321.1425, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████▉                                  | 30/49 [00:06<00:03,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(286.0846, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████▋                                | 31/49 [00:06<00:03,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(350.6438, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████▍                              | 32/49 [00:06<00:03,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(358.3927, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████▎                            | 33/49 [00:06<00:03,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(339.0778, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████████████████████████████████████                           | 34/49 [00:06<00:03,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(336.7331, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████▊                         | 35/49 [00:07<00:02,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(334.9448, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████▋                       | 36/49 [00:07<00:02,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(398.1593, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████████▍                     | 37/49 [00:07<00:02,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(170.7106, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████████▏                   | 38/49 [00:08<00:03,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(174.4048, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████████                  | 39/49 [00:08<00:02,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(388.8571, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████████▊                | 40/49 [00:08<00:02,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(178.0180, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████████████▋              | 41/49 [00:08<00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(312.0809, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████████████▍            | 42/49 [00:08<00:01,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(450.4752, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████████████▏          | 43/49 [00:09<00:01,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(365.2820, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████         | 44/49 [00:09<00:01,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(343.7886, device='cuda:0')\n",
      "tensor(379.5918, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████████▌     | 46/49 [00:09<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(325.9454, device='cuda:0')\n",
      "tensor(386.7509, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:10<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(399.3810, device='cuda:0')\n",
      "tensor(156.6232, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vqvae_model.eval()\n",
    "val_loss_ae = {}\n",
    "cnt = 0\n",
    "codebook_usage = {i: 0 for i in range(vqvae_args.codebook_size )}\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(\n",
    "        (train_loader),\n",
    "        position=0,\n",
    "        leave=True,\n",
    "    ):\n",
    "        gt_motion = batch[\"motion\"][0].to(device)\n",
    "\n",
    "        # indices = vqvae_model.encode(\n",
    "        #     motion=gt_motion,\n",
    "        #     # mask=mask,\n",
    "        # )\n",
    "\n",
    "        # used_indices = indices.flatten().tolist()\n",
    "        out = vqvae_model(\n",
    "            motion=gt_motion,\n",
    "            # mask=mask,\n",
    "        )\n",
    "\n",
    "        out.perplexity = vqvae_model.vqvae.quantizer.compute_perplexity(out.indices.flatten())\n",
    "        print(out.perplexity)\n",
    "\n",
    "        used_indices = out.indices.flatten().tolist()\n",
    "        unique_indices, counts = torch.unique(out.indices.flatten(), return_counts=True)\n",
    "        for idx, count in zip(unique_indices, counts):\n",
    "            codebook_usage[idx.item()] += count.item()\n",
    "        usage = len(set(used_indices)) / vqvae_args.codebook_size \n",
    "        # print(out.perplexity)\n",
    "\n",
    "        loss_dict = {\n",
    "            # \"total_loss\": loss.detach().cpu(),\n",
    "            # \"loss_motion\": loss_motion.detach().cpu(),\n",
    "            # \"commit_loss\": vqvae_output.commit_loss.detach().cpu(),\n",
    "            \"usage\": usage,\n",
    "            \"perplexity\": out.perplexity\n",
    "        }\n",
    "\n",
    "        cnt+=1\n",
    "\n",
    "        for key, value in loss_dict.items():\n",
    "            if key in val_loss_ae:\n",
    "                val_loss_ae[key] += value\n",
    "            else:\n",
    "                val_loss_ae[key] = value\n",
    "\n",
    "\n",
    "for key in val_loss_ae.keys():\n",
    "    val_loss_ae[key] = val_loss_ae[key] / cnt\n",
    "\n",
    "total_usage = sum(codebook_usage.values())\n",
    "average_usage_per_index = total_usage / vqvae_args.codebook_size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04ad3774-0bf4-43b6-aba2-a2b8ac428a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage': 0.5695153061224489, 'perplexity': tensor(311.0792, device='cuda:0')}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ba0b972-0c0a-4dd2-9172-81328aea0168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141.328125"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_usage_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "986440ac-84fc-4d7f-b36c-2bf0a93cc615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list(codebook_usage.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780ec13-3fe8-4f60-9cda-cfeb1f309a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "682f3d4b-f635-4590-8ec3-8cc4bf2281b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1024 artists>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = list(codebook_usage.keys())\n",
    "usage_counts = list(codebook_usage.values())\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(indices, usage_counts, color='skyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbb878-3d8f-4951-8611-2071cb893c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a85e09d6-84ef-49b1-897c-b4bba49a67d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage': 0.6187420280612245, 'perplexity': tensor(381.2243, device='cuda:0')}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17b01a49-d07c-4f10-884a-f9a40e900425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141.328125"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_usage_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddcd20dd-3d29-42b2-96db-0f84c27a22d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list(codebook_usage.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19fa8246-ba07-4856-ba29-92eaaf3fa067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1024 artists>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = list(codebook_usage.keys())\n",
    "usage_counts = list(codebook_usage.values())\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(indices, usage_counts, color='skyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c3f787-4973-4717-a688-b100153bd00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34ae036a-221e-4743-9988-33a5f1cb3a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de5cfe9-7411-443d-8358-fad9a0a17bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c1b27b1-2094-484f-a5ac-5d29288cc4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74734c6-db87-4673-83c8-9f7defb2b990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 768000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7f59a73-7afb-477b-82e2-983b11b0dca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92462a59-e417-4d1f-acae-ac79b143db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_sum = embed * rearrange(cluster_size, \"... -> ... 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3190d725-2b7e-41bb-8bdf-3d86974991b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 768000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_sum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a89bfa-687b-44dd-b498-a43e0ef7b816",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Motion Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a735ceed-be47-460e-96c0-da344db04f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider, ConditionFuser\n",
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "from core.models.generation.motion_generator import Transformer, MotionMuse\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dad8049-a4a0-4612-97ae-06e6e22ffb25",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Non-existent config key: codebooks_pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cfg_defaults \u001b[38;5;28;01mas\u001b[39;00m get_cfg_defaults3\n\u001b[1;32m      4\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_cfg_defaults()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_streaming/motion_streaming.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m cfg\u001b[38;5;241m.\u001b[39mfreeze()\n\u001b[1;32m      7\u001b[0m mmuse_args \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mmotion_generator\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/yacs/config.py:213\u001b[0m, in \u001b[0;36mCfgNode.merge_from_file\u001b[0;34m(self, cfg_filename)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cfg_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    212\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_cfg(f)\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_from_other_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/yacs/config.py:217\u001b[0m, in \u001b[0;36mCfgNode.merge_from_other_cfg\u001b[0;34m(self, cfg_other)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_from_other_cfg\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg_other):\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Merge `cfg_other` into this CfgNode.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[43m_merge_a_into_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/yacs/config.py:491\u001b[0m, in \u001b[0;36m_merge_a_into_b\u001b[0;34m(a, b, root, key_list)\u001b[0m\n\u001b[1;32m    489\u001b[0m     root\u001b[38;5;241m.\u001b[39mraise_key_rename_error(full_key)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-existent config key: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(full_key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Non-existent config key: codebooks_pattern'"
     ]
    }
   ],
   "source": [
    "from configs.config_t2m import cfg, get_cfg_defaults\n",
    "from configs.config import get_cfg_defaults as get_cfg_defaults3\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_generation/motion_generation.yaml\")\n",
    "cfg.freeze()\n",
    "mmuse_args = cfg.motion_generator\n",
    "dataset_args = cfg.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c174676-b3a5-424c-a6a7-212b1960263d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m target \u001b[38;5;241m=\u001b[39m mmuse_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m motion_muse \u001b[38;5;241m=\u001b[39m MotionMuse(mmuse_args)\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "target = mmuse_args.pop(\"target\")\n",
    "motion_muse = MotionMuse(mmuse_args).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8441fb76-675e-4500-ab2f-2d528507c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.resnetVQ.vqvae import HumanVQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e17fa70-7497-441b-bfc2-6f80c4315101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vcfg = get_cfg_defaults3()\n",
    "vcfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_body_gprvc/vqvae_body_gprvc.yaml\")\n",
    "vqvae_args = vcfg.vqvae\n",
    "vqvae_args.nb_joints = 22\n",
    "vqvae_args.motion_dim = 263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2fcee-d2d4-4428-b66e-da75989882f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153aab1a-472c-4f32-9477-7cef6c60c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.split(np.cusum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5fb8d3b-a01c-4d29-8c2b-635e1daf80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_model = HumanVQVAE(vqvae_args).to(device).eval()\n",
    "vqvae_model.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ACMG/checkpoints/smplx_resnet/vqvae_motion.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ab9d2-a089-48ef-b155-7b58f558ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a1f7b4-6181-4bbf-be86-53f21f954486",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=10,\n",
    "            audio_max_length_s=10,\n",
    "            pad_id = motion_muse.transformer.pad_token_id,\n",
    "            fps=30/4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b646cf7c-5536-43f8-98dc-335c8791ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bod_ind = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/indices/body/aist/subset_0000/Dance_Break_3_Step_clip_1.npy\")\n",
    "lh_ind = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/indices/left_hand/aist/subset_0000/Dance_Break_3_Step_clip_1.npy\")\n",
    "rh_ind = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/indices/right_hand/aist/subset_0000/Dance_Break_3_Step_clip_1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e52a53-c80a-44cc-b2d3-c89a18eb081b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e30407-e8e1-4e05-8fe1-28f95c5eec4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a0df4-f265-41b5-9577-5162b7e262f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4d76d-6cc5-4fe2-bd4b-7b5984f591eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e44106b1-f9a2-45cb-9a2e-e20773e110f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions animation: 268 and texts 268\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "\n",
    "dset = MotionIndicesAudioTextDataset(\"animation\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"full\", split = \"train\" , fps = 30/4  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f05f6af-6eec-4961-a203-8e3ec4d07d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpss  = next(iter(dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67996729-7f6f-4f75-a95f-adda0b498f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions animation: 73 and texts 73\n",
      "Total number of motions choreomaster: 34 and texts 34\n"
     ]
    }
   ],
   "source": [
    "train_ds, sampler_train, weights_train  = load_dataset_gen(dataset_args=dataset_args, split = \"train\" , dataset_names = [\"animation\" , \"choreomaster\" ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dc88a-d090-4ebf-831e-b0054072e83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29b1d3c1-2084-4c57-bd85-b391f57e418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dset,\n",
    "        4,\n",
    "        # sampler=sampler_train,\n",
    "        # shuffle = False,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider),\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce18ef6b-8c40-4b3e-b4b4-704d756b863d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for inputs, conditions in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c08cbf2-99c4-4355-8c0f-e1cb331e32b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 75, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7693e02-e1e4-4840-b20f-2ab6a0cddd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 75])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"motion\"][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a017d85-0ab0-4542-8338-93e66c6efd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 500, 128])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22949664-9e06-41e8-9368-c533a5a445a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 768])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb4cb22e-4566-4f10-95a4-d3b6e62d3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions = inputs[\"motion\"][0].squeeze().to(torch.long)\n",
    "motion_mask = inputs[\"motion\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d6f90a96-5765-4831-a80a-6a4bb12e2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_method = {\"cross\": [\"audio\"], \"prepend\": [\"text\"]}\n",
    "condition_fuser = ConditionFuser(fuse_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41376d0a-fdff-4503-a5fb-38167a369969",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed = self.project_audio(conditions[\"audio\"][0])\n",
    "text_embed = self.project_text(conditions[\"text\"][0])\n",
    "\n",
    "inputs_, cross_inputs = self.condition_fuser(\n",
    "    input,\n",
    "    {\n",
    "        \"text\": (text_embed, conditions[\"text\"][1]),\n",
    "        \"audio\": (audio_embed, conditions[\"audio\"][1]),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c731b-4240-4537-a4b7-0baff3c201e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ed176-a935-4fbd-93d6-b004c5768f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af848aa-93f8-487b-ad27-83c6ea2ec1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4261c42-9d36-49ee-b4de-b47996f33721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da28d2c-8543-4356-8644-37db1a506519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227c9af-4388-4331-b300-38aa8c292b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe478ffa-20be-4503-a905-c3d7e3105b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 75, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "832689e8-645f-4e2a-8fda-b696a57edee2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MotionMuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e21289cf-8d3d-4bd7-8294-8f526ecd4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss , logits = motion_muse((motions , motion_mask) , conditions , cond_drop_prob = 0.4 , return_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7565e36-238b-4dab-8fc2-f0d626b1c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_indices = lologits.argmax(-1)\n",
    "pred_motion  = vqvae_model.decode(pred_indices[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e5cf9-2d15-4c2b-bd87-a8a09932ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17c774f5-60ca-4131-ac61-4d8d288e9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_motion = torch.where(motions >= 1024 , 0 , motions)\n",
    "gt_motion  = vqvae_model.decode(mod_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a2f0d8a-23f2-4001-b561-a499280742cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 263])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_motion[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ba8f456-13d1-4ee7-861e-35e7409b9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.render_hml(\n",
    "                    gt_motion[1][:(int(sum(motion_mask[1])) *4)].detach().squeeze().cpu(),\n",
    "                    \"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/gt_motion_recon.gif\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908211ad-edac-4671-804c-82378aca2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits2 = motion_muse.transformer.forward_with_cond_scale((motions , motion_mask) , conditions)\n",
    "logits3 =motion_muse.transformer.forward_with_neg_prompt((motions , motion_mask) , conditions , conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b4bafcb-4dae-41bd-bb35-4eec9411eff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12cc9378-24d1-4a80-8127-0f37701e8195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d4446cd2-9d83-4c0a-91fb-308d3a1fe43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "abdc0dd2-6fd3-4ee1-9c31-64d26aa47fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8823b0-c190-40b4-b8db-9af144202f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "941f570a-d0d2-4fca-8631-abb6f1e97084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 18/18 [00:01<00:00, 14.65it/s]\n"
     ]
    }
   ],
   "source": [
    "gen_ids = motion_muse.generate(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad7f38-68a5-470f-be70-49271deb6e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a8e7ed-a9d6-4fb5-a45a-187c48ce1f72",
   "metadata": {},
   "source": [
    "## Streaming transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1e61c8-9de6-4062-a444-aa0c41b2700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from core.param_dataclasses import pattern_providers\n",
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c76b02d-2c79-45aa-a014-dd65ec93cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from core.models.generation.lm import LMModel, MotionGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d9572-d125-45c7-9892-9383fefc386f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd0ef0b8-3678-44b1-9ff8-38e3edaf6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_streaming import cfg, get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_streaming/motion_streaming.yaml\")\n",
    "# cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3dec2ab9-311e-46a7-ae4c-262399be4c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.transformer_lm.custom = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3e7b5a3-d60d-4902-8e47-83797a5ed0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_args = cfg.transformer_lm\n",
    "target = lm_args.pop(\"target\")\n",
    "fuse_config = cfg.fuser\n",
    "pattern_args = cfg.codebooks_pattern\n",
    "dataset_args = cfg.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00544a2c-cf08-4e84-a84a-8313866c9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen= MotionGen(lm_args , fuse_config , pattern_args ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b3749c8e-0eca-48fd-ba1b-3046cb83b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = pattern_args.pop(\"modeling\")\n",
    "pattern_provider = pattern_providers[modeling](lm_args.n_q, delays = pattern_args.delays , flatten_first = pattern_args.flatten_first , empty_initial = pattern_args.empty_initial )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc42ef-4be4-4bd5-8618-6e6681e52706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a160f9be-3dbb-4b6c-a0bf-bf372f2ae3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_method = fuse_config.pop(\"fuse_method\")\n",
    "if isinstance(fuse_method, list):\n",
    "    fuse_method = fuse_method[0]\n",
    "condition_fuser = ConditionFuser(fuse_method, **fuse_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb9d56-c713-404a-85e5-69c9b4b015a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f861be10-8c39-4080-a103-855c3483316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LMModel(\n",
    "            pattern_provider=pattern_provider,\n",
    "            fuser=condition_fuser,\n",
    "            **lm_args\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a0493-4f58-478a-a699-02f62d0be73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b78ac803-29ae-4456-9240-baff9c69d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom attention took 0.5189828872680664 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    out = model.compute_predictions(inputs[\"motion\"] , conditions)\n",
    "end = time.time()\n",
    "print('custom attention took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218e730-e54f-4414-9589-ecad361bb355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b0c40-b94f-476d-8317-bba9a904829c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a49bd9-1160-4181-8512-b6e4b3973a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3493b2d-800b-4c06-a117-c5a81b89ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "def _compute_cross_entropy(\n",
    "     logits: torch.Tensor, targets: torch.Tensor, mask: torch.Tensor\n",
    ") -> tp.Tuple[torch.Tensor, tp.List[torch.Tensor]]:\n",
    "    \"\"\"Compute cross entropy between multi-codebook targets and model's logits.\n",
    "    The cross entropy is computed per codebook to provide codebook-level cross entropy.\n",
    "    Valid timesteps for each of the codebook are pulled from the mask, where invalid\n",
    "    timesteps are set to 0.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): Model's logits of shape [B, K, T, card].\n",
    "        targets (torch.Tensor): Target codes, of shape [B, K, T].\n",
    "        mask (torch.Tensor): Mask for valid target codes, of shape [B, K, T].\n",
    "    Returns:\n",
    "        ce (torch.Tensor): Cross entropy averaged over the codebooks\n",
    "        ce_per_codebook (list of torch.Tensor): Cross entropy per codebook (detached).\n",
    "    \"\"\"\n",
    "    B, K, T = targets.shape\n",
    "    assert logits.shape[:-1] == targets.shape\n",
    "    assert mask.shape == targets.shape\n",
    "    ce = torch.zeros([], device=targets.device)\n",
    "    ce_per_codebook: tp.List[torch.Tensor] = []\n",
    "    for k in range(K):\n",
    "        logits_k = (\n",
    "            logits[:, k, ...].contiguous().view(-1, logits.size(-1))\n",
    "        )  # [B x T, card]\n",
    "        targets_k = targets[:, k, ...].contiguous().view(-1)  # [B x T]\n",
    "        mask_k = mask[:, k, ...].contiguous().view(-1)  # [B x T]\n",
    "        ce_targets = targets_k[mask_k]\n",
    "        ce_logits = logits_k[mask_k]\n",
    "        q_ce = F.cross_entropy(ce_logits, ce_targets)\n",
    "        ce += q_ce\n",
    "        ce_per_codebook.append(q_ce.detach())\n",
    "    # average cross entropy across codebooks\n",
    "    ce = ce / K\n",
    "    return ce, ce_per_codebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b40dde6-abbd-41d5-82ec-2835fc4118e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=10,\n",
    "            audio_max_length_s=10,\n",
    "            pad_id = model.pad_token_id,\n",
    "            fps=30/4,\n",
    "            # device = \"cpu\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc8d1fa-a114-4d34-9deb-77f40e573f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions animation: 268 and texts 268\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "dset = MotionIndicesAudioTextDataset(\"animation\" , \"/srv/hays-lab/scratch/sanisetty3/motionx\" ,motion_rep = \"full\", split = \"train\" , fps = 30/4  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f678ef65-eb0b-4491-b383-3bc9af5a03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds, sampler_train, weights_train  = load_dataset_gen(dataset_args=dataset_args, split = \"train\" , dataset_names = [\"animation\" , \"choreomaster\" ] )\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dset,\n",
    "        4,\n",
    "        # sampler=sampler_train,\n",
    "        # shuffle = False,\n",
    "        collate_fn=partial(simple_collate , conditioner = condition_provider , permute = True),\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe674256-814a-44a7-8d56-bf6b243d2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc814c-aa4f-464e-9d76-471a18a2249e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b78ff3-d6c7-423c-b991-8fdeb637d096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d3ae41f-e73e-4543-814f-a2ce73f0b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask = inputs[\"motion\"][1]\n",
    "motions_or_ids = inputs[\"motion\"][0]\n",
    "B, K, T = motions_or_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33b546b-0225-4bf1-a579-af34eba142c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"text\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "212a21a7-3d15-4cc8-8a51-e283c4edc36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa9639-b1ff-4710-a1ea-3b3c893cef85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af1054-aaba-4917-83b6-be181fd5b804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddc6ea24-2f62-4acc-a732-9a4e6c607542",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss, ce_per_codebook = model_gen(inputs[\"motion\"] , conditions, return_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75e4cc30-38a1-491c-b393-c9510e97989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, conditions in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd0a86f-6bbf-43bb-a92d-c91e75552e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn((4, 54, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad05e44d-f4a9-47fa-90d7-3e85de089177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_mas(query.shape[1], query.device, query.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d490c460-e444-4a4b-beb5-b6834b0d2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(i, j=None, device=\"cuda\"):\n",
    "    if j is not None and i != j:\n",
    "        mask = torch.zeros((i, j), device=device, dtype=torch.bool)\n",
    "\n",
    "        scale = j / i\n",
    "\n",
    "        # num_masked_elements = torch.arange(\n",
    "        #     int(round(scale)), int(round(scale * i)) + 1, int(round(scale))\n",
    "        # )\n",
    "        strt = 1 if scale < 1 else int(round(scale))\n",
    "        num_masked_elements = torch.linspace(strt, j + 1, i)\n",
    "\n",
    "        for idx, num in enumerate(num_masked_elements[:i]):\n",
    "\n",
    "            mask[idx, int(num) :] = True\n",
    "        return mask\n",
    "\n",
    "    return torch.ones((i, i), device=device, dtype=torch.bool).triu(i - i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a14e6f8-726c-4077-a57d-e2ef79f36efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = create_causal_mask(3, device = \"cuda\")\n",
    "key_padding_mask = input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9d5082d-4f29-42d7-965e-0de25f40ed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a52a2fba-9fb9-43f1-b41a-6846d8e71f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_value = -torch.finfo(torch.float).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d30f2e4a-076e-4a33-80e7-2dc5f5081014",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_padding_mask = rearrange(key_padding_mask, \"b j -> b 1 1 j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a3f93b5-06f0-419e-af74-d31ad8c24228",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = repeat(attn_mask, \"i j -> b 1 i j\", b=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7998609-037b-4e81-ac3e-7aa866dc7cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5982cb57-3f8f-4498-a312-33f5d1011d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_padding_mask2 = torch.where(~key_padding_mask , mask_value , 0  )\n",
    "attn_mask2 = torch.where(attn_mask , float(\"-inf\") , 0  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68d46edd-2a04-4f40-bc0b-f8dc1b0b6f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask2.to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1de11-db21-4ce6-9cff-175991266b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b374fd9-6488-4ef5-b4bd-c975c620cc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f1487-6119-4c26-927a-aa2b00f2885d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4568d9-bc05-497c-a1f6-acd5daac1ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae0039-4a36-4130-ba7a-7974783611bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8470b40-073a-4353-a651-99af8be59f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 54, 512]) torch.Size([4, 54, 512])\n",
      "torch.Size([54, 54]) torch.float32\n",
      "torch.Size([4, 54]) torch.bool\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_get_mask() got multiple values for argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmotion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom attention took \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(end \u001b[38;5;241m-\u001b[39m start))\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/generation/lm.py:499\u001b[0m, in \u001b[0;36mLMModel.compute_predictions\u001b[0;34m(self, inputs, condition_tensors, stage, keep_only_valid_steps, cond_drop_prob)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# apply model on pattern sequence\u001b[39;00m\n\u001b[1;32m    498\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fsdp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fsdp\n\u001b[0;32m--> 499\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_codes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_new_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond_drop_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_drop_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, K, S, card]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# print(logits)\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# map back the logits on pattern sequence to logits on original codes: [B, K, S, card] -> [B, K, T, card]\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# and provide the corresponding mask over invalid positions of tokens\u001b[39;00m\n\u001b[1;32m    508\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [B, card, K, S]\u001b[39;00m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/generation/lm.py:425\u001b[0m, in \u001b[0;36mLMModel.forward\u001b[0;34m(self, inputs, condition_tensors, stage, cond_drop_prob)\u001b[0m\n\u001b[1;32m    422\u001b[0m context \u001b[38;5;241m=\u001b[39m cross_attention_input[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    423\u001b[0m context_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcross_attention_input[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 425\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_src\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# src_mask=(self.attn_mask_per_stage[stage] if stage >= 0 else None),\u001b[39;49;00m\n\u001b[1;32m    431\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_norm:\n\u001b[1;32m    433\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_norm(out)\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/generation/streaming_transformer/transformer.py:846\u001b[0m, in \u001b[0;36mStreamingTransformer.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_scale \u001b[38;5;241m*\u001b[39m pos_emb\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 846\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_streaming:\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets \u001b[38;5;241m+\u001b[39m T\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/generation/streaming_transformer/transformer.py:798\u001b[0m, in \u001b[0;36mStreamingTransformer._apply_layer\u001b[0;34m(self, layer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointing\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_checkpoint(layer, \u001b[38;5;241m*\u001b[39margs, use_reentrant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/generation/streaming_transformer/transformer.py:643\u001b[0m, in \u001b[0;36mStreamingTransformerLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, cross_attention_src, cross_key_padding_mask)\u001b[0m\n\u001b[1;32m    640\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n\u001b[1;32m    642\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_scale_1(\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m     )\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cross_attention_src \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    646\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_scale_cross(\n\u001b[1;32m    647\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross_attention_block(\n\u001b[1;32m    648\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_cross(x), cross_attention_src, cross_key_padding_mask\n\u001b[1;32m    649\u001b[0m             )\n\u001b[1;32m    650\u001b[0m         )\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/transformer.py:722\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    721\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 722\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/generation/streaming_transformer/transformer.py:408\u001b[0m, in \u001b[0;36mStreamingMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m    405\u001b[0m         query, key, value \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [query, key, value]]\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly same key value suppoted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 408\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/attend2.py:349\u001b[0m, in \u001b[0;36mCustomMHA.forward\u001b[0;34m(self, q, k, v, key_padding_mask, rel_pos)\u001b[0m\n\u001b[1;32m    345\u001b[0m     attn_bias \u001b[38;5;241m=\u001b[39m rel_pos(i, j)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# print(q.shape, k.shape, v.shape, input_mask.shape)\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m out \u001b[38;5;241m=\u001b[39m rearrange(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h n d -> b n (h d)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_out(out)\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/attend2.py:212\u001b[0m, in \u001b[0;36mAttend.forward\u001b[0;34m(self, q, k, v, mask, attn_bias)\u001b[0m\n\u001b[1;32m    205\u001b[0m     k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m t: repeat(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb kvh n d -> b (r kvh) n d\u001b[39m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m=\u001b[39mheads \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m kv_heads),\n\u001b[1;32m    207\u001b[0m         (k, v),\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflash:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflash_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m kv_einsum_eq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb j d\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h j d\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m dots \u001b[38;5;241m=\u001b[39m einsum(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h i d, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkv_einsum_eq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> b h i j\u001b[39m\u001b[38;5;124m\"\u001b[39m, q, k) \u001b[38;5;241m*\u001b[39m scale\n",
      "File \u001b[0;32m/coc/scratch/sanisetty3/music_motion/ATCMG/core/models/attend2.py:133\u001b[0m, in \u001b[0;36mAttend.flash_attn\u001b[0;34m(self, q, k, v, mask, attn_bias)\u001b[0m\n\u001b[1;32m    130\u001b[0m row_is_entirely_masked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exists(mask) \u001b[38;5;129;01mand\u001b[39;00m causal:\n\u001b[0;32m--> 133\u001b[0m     causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_causal_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m~\u001b[39mcausal_mask\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# protect against an entire row being masked out\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: _get_mask() got multiple values for argument 'device'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    out = model.compute_predictions(inputs[\"motion\"] , conditions)\n",
    "end = time.time()\n",
    "print('custom attention took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e66e0dc-d743-4da6-afbd-3aacd5d918d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch attention took 0.45839786529541016 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    out = model.compute_predictions(inputs[\"motion\"] , conditions)\n",
    "end = time.time()\n",
    "print('torch attention took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00118e07-384d-45b0-b8fc-ecfda0545d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7ca6fa3-696e-44fa-a980-9d14e1564e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4837, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72ecdff3-035e-4de1-a9c7-e071841ffc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(7.6227, device='cuda:0'),\n",
       " tensor(7.1723, device='cuda:0'),\n",
       " tensor(7.6560, device='cuda:0')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_per_codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3f30e-3c3f-4c65-aa53-ffab3f9b032c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09223a9f-75d1-47d0-a5a8-e95f22bafbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f10cf3-7354-41a4-9387-2cbdc6e0311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637bf6a-df0b-4cd8-a5df-93164ea093ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13badad5-dd42-4fc7-8cd3-4eef258908f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.where(motions_or_ids == 1024 , -100 , motions_or_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26e7c4-560c-476f-bfc8-47c7410f4c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "062a2b80-c568-4da7-a583-ec78ad068892",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "            input_mask.unsqueeze(1).expand(-1, K, -1).contiguous() & out.mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8e398ec-c297-48e3-9419-6d63b0f501fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce, ce_per_codebook = _compute_cross_entropy(out.logits, target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "311f4454-9212-486a-9b28-3f0f5162f320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5305, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "406e54e5-5508-4c75-9037-58385cea021c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(7.4742, device='cuda:0'),\n",
       " tensor(7.8424, device='cuda:0'),\n",
       " tensor(7.2748, device='cuda:0')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_per_codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4c04a20b-63fb-4741-b6d4-25a69835a826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4feeba5d-cd88-4da8-b3b1-fa6aa37aed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = cfg_s.transformer_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e725d30c-b766-4f13-a77c-c9a6e1a8f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = MotionTokenizerParams(model_cfg.card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3de950ca-b389-492b-a5dd-442ffefc7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_q = 3\n",
    "codes = inputs[\"motion\"][0].permute(0,2,1).to(torch.long)\n",
    "code_mask = inputs[\"motion\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91b54732-8ba6-4285-9c9f-9b2f438329f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, K, T = codes.shape\n",
    "codes = codes.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "315e1a5f-4d3b-469a-be18-acdc7d3653d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 52])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bb884ad-ec84-4b05-8932-c879432c1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = pattern_provider.get_pattern(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd4a31af-5302-4ac8-b55f-37ce3d633d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 52])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2affa79-d5a2-4c1a-a109-c0c1a3fc8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_codes, sequence_indexes, sequence_mask = (\n",
    "            pattern.build_pattern_sequence(\n",
    "                codes,\n",
    "                1025,\n",
    "                keep_only_valid_steps=True,\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb69c415-f1c7-4344-bb23-8a71add2b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 53])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66154dbc-7ca8-427a-9840-c09f2ea8f3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 52])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "273247a6-8017-423d-8a25-1acd03285ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 53])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e134f8e-af23-46e1-80f9-9505d5707e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask = torch.ones_like(sequence_mask).repeat(B , 1 , 1)\n",
    "for i in range(n_q):\n",
    "    new_mask[:,i,i+1:] = code_mask[:,0:T-i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dd667-48bf-455c-9ead-a85f92113b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "784fe530-6f4d-4dd2-8661-c97222c0da70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 53])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67188e6-85eb-41e4-b513-2cfc605bed54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a02a6b4-f643-40ec-931c-27be67587d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_mask = (new_mask.sum(1) == new_mask.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9728a38-64b0-4829-a2a9-de1a394e3b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_new_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba620f8-607f-4868-87d1-bdbd8bad7a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "140792f0-0b9c-435e-88da-375174357c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.audio_encoders import AudioConditionerEncodec, AudioConditionerLibrosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bec8-3c58-4545-9d18-2619f7a4bd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48afcbc2-375e-4d95-b97a-6ef27a397749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "audenc = AudioConditionerEncodec()\n",
    "audlib = AudioConditionerLibrosa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c17c903-36ce-4813-9cb9-152a4981422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = audenc(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/choreomaster/0071.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19a7f591-a7e0-4722-8dcd-5d1c309e5495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb2 = audlib(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/choreomaster/0071.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3a77f68-dd04-467d-8c5c-dc32e5dd48cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5234, 35)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef4f8574-6d24-4b59-a0a6-89a98b931161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8722, 128])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e882bae-0397-4dfc-928e-c8b6573bed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = np.load(\"/srv/hays-lab/scratch/sanisetty3/motionx/audio/encodec/choreomaster/0071.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a75f834f-ad5b-4cf5-96b0-255d87859e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8722, 128)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee279589-0afd-4a15-a330-59b31ded62f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719f563-d54a-4915-9e0e-b9b850a08a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb755de3-c832-4cc4-90d3-e7f8bfa9478e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49a7f02f-f040-4573-ae44-fb1bc82c0b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2777bc6f-bb65-4ef9-8e42-38d07a23a598",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m librosa\u001b[38;5;241m.\u001b[39monset\u001b[38;5;241m.\u001b[39monset_strength(y \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSR)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "librosa.feature.chroma_cens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e00477fe-6323-41d6-b575-8facf269b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn((4 , 1024 , 3 , 53))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63fa3dcc-8e78-456b-a375-6e9808c1ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, logits_indexes, logits_mask = pattern.revert_pattern_logits(\n",
    "            logits, float(\"nan\"), keep_only_valid_steps=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2f37e2d-b4b8-4385-a7b7-f6dc66552861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4b65e0a8-6f4d-467f-ae3f-5ebabf0bbbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024, 3, 52])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb49e077-1c92-4af7-bd67-964f834a8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = logits.permute(0, 2, 3, 1)  # [B, K, T, card]\n",
    "logits_mask = logits_mask[None, :, :].expand(B, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd2fe245-d862-44c5-8e9e-35daca659c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 52, 1024])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cd0f5-abac-4847-93f6-f95902d70bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a66078-e651-47dd-9d95-b01f6fed9e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d41caf-6b60-4498-81e6-07f31616d1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e7eaf4-8d3e-44d0-a0c9-6809baa88a06",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301ed47-259c-4850-a3b0-370b41eab8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"a man dancing\"\n",
    "audio = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45e2f84f-c52a-475c-8614-fccf5bd609da",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud , am = condition_provider._get_audio_features(audio_list = [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7505174-0e14-4765-a886-e6b2de615524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72854d41-ae2e-4b22-9967-479e5151b4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc74f7-78e4-4401-880d-7cb73ba151b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d5ff5-310c-4604-bdbe-2baa537d08c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a08eab58-a9aa-4b5f-8e8a-8f10b395752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sap = AttentionParams(dim = 256 , causal=True)\n",
    "cap = AttentionParams(dim = 256 , causal=True , add_null_kv=True)\n",
    "transformer_params = TranslationTransformerParams(self_attention_params = sap , \n",
    "                                                  cross_attention_params = cap , \n",
    "                                                  depth = 1, \n",
    "                                                  positional_embedding_params=PositionalEmbeddingParams(dim = 256) , \n",
    "                                                  positional_embedding=PositionalEmbeddingType.SINE,\n",
    "                                                  fuse_method = {\"cross_seperate\" : [\"audio\" , \"text\"]}\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630d974-93d0-4280-95bd-af6608b7c25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36579128-c825-4f7e-9416-b852d8536cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = transformer_blocks(\n",
    "            x=x_,\n",
    "            mask=x_padding_mask,\n",
    "            context=context,\n",
    "            context_mask=context_padding_mask,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "557f7668-0ab2-47de-8f5b-3389a5c0751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embed[:, -n:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2e0c1b4-5cd3-494e-b89e-7cb40efd70fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116, 256])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e4741-b259-4a50-a2ae-4ebf7ac1a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenCLIPEmbedder(nn.Module):\n",
    "    \"\"\"Uses the CLIP transformer encoder for text (from Hugging Face)\"\"\"\n",
    "    def __init__(self, version=\"openai/clip-vit-large-patch14\", device=\"cuda\", max_length=77):\n",
    "        super().__init__()\n",
    "        self.tokenizer = CLIPTokenizer.from_pretrained(version)\n",
    "        self.transformer = CLIPTextModel.from_pretrained(version)\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.freeze()\n",
    "\n",
    "    def freeze(self):\n",
    "        self.transformer = self.transformer.eval()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, text):\n",
    "        batch_encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, return_length=True,\n",
    "                                        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        tokens = batch_encoding[\"input_ids\"].to(self.device)\n",
    "        outputs = self.transformer(input_ids=tokens)\n",
    "\n",
    "        z = outputs.last_hidden_state\n",
    "        return z\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de48aa-bc99-4d66-921d-da96baa01e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38264d9e-7b0e-450c-a8fd-45464f90a4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16676f3f-c4e0-402e-8192-79b24528c866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f85cfd87-d174-419a-81d7-895447c01313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = ScaledSinusoidalEmbedding(PositionalEmbeddingParams(dim = 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "983afa5c-2dc2-4733-8081-3e7e644bd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b , n , _ = input[\"motion\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c64a3-ce84-40d1-bbe3-541aa798a582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d934f4b8-0532-4a3f-9382-507fc14f2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = pos_emb(input[\"motion\"][0]).repeat(b , 1 ,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ce8b3c55-1c80-493f-bf3f-d1515d2e4807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 116, 256])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb8349-57bd-482e-b00a-36fcc5670155",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, (b , c) in conditions.items():\n",
    "    print(a)\n",
    "    print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a53af4-0e65-4077-a1a2-a19f9cef26c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bb9f8cd0-8e0f-470a-8fc3-c02969b2f06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_ , cross_inputs = condition_fuser(x , conditions  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ee340a5a-6b33-43fc-8e74-e165409b7731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 153, 256])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2a8b199b-04a9-4597-90b0-ed420188c671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 500, 256])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62191059-8fe0-489d-9fd9-04bdc9dd805b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
